## Мысли и советы из книги Sam Newman "Building Microservices"

1. **Bounded context** из DDD отлично описывает один микросервис. Если определить все главные **bounded contexts**, то можно каждый выделить в сервис, а каждый сервис может содержать свои внутренние **bounded contexts**.

2. Систему можно начинать проектировать и делать как монолитную в одном солюшне для того чтобы постепенно проявить все внутренние (использующиеся внутри сервиса) и внешние (использующиеся для передачи данных между сервисами) **модели** и **bounded contexts**. Затем, когда все проясниться и устаканиться, можно ее (систему) разбить на микросервисы. **Это совет для новичков**. С опытом систему можно сразу проектировать как микросервисную.

3. При проектировании микросервисов необходимо думать в **контексте возможностей (capabilities)** проектируемого сервиса и того **что он умеет делать**, а не данных которыми он оперирует, иначе выйдет просто CRUD вокруг которого строится сервис. А когда эти возмоности и способности определены - уже можно выделять данные и модели, которые нужны для реализации этих спосбностей.

4. Вариант общения клиента и сервера: гуглить **Richardson Maturity Model и Hypermedia Controls (HATEOAS)**. Фаулер об этом писал, подход прикольный, но походу не получил популярность.

5. Микросервисы должны иметь **low coupling** между друг другом и **high cohesion** внутри себя, что логично. Но **shared** между сервисами база данных или **библиотека с data types** для всех сервисов в итоге неявно увеличивает **coupling**. Кроме того, создание библиотеки клиента для сервиса и использование ее в разных клиентах этого сервиса тоже создает **coupling** между **ВСЕМИ** клиентами и сервисом. Принцип **DRY** тоже можно и нужно нарушать в угоду независимости сервисов друг от друга. Лучше скопипастить какой-то кусок кода с бизнес логикой чем выделять его в библиотеку и шарить ее между сервисами (речь не идет вспомогательных библиотеках типа log4net).

6. Согласно автору **асинхронная event-based** коммуникация между микросервисами через **message broker** типа Rabbit MQ является лучшим вариантом реализации архитектуры микросервисов, так как имеет наименьший **coupling** и микросервисы не знают друг о друге.

7. UI layer за которым стоит множество микросервисов может общаться с ними следующим образом:
	* UI компонент, который шлет запросы всем необходимым сервисам
		- &#9989; SRP - UI сам за себя отвечает и знает что ему нужно
		- &#10060; сообщения могут слаться рассинхронизированно, что жрет много трафика, что критично для мобильной сети
		- &#10060; для получения всей информации надо общаться с несколькими сервисами, т.е. происходит интенсивное использование сети
		- &#10060; скорее всего понадобиться выделенная команда для поддержи UI, а это значит необходима коммуникация между командами, теряется независимость
		- &#10060; увеличиватся **coupling** между сервисами и UI
	
	* Каждый сервис представляет свой UI виджет. Все они собираются в некий box и показываются пользователю.  
		- &#9989; UI каждого сервиса сапортится командой этого сервиса и нет нужды в выделенной UI команде
		- &#9989; **coupling** между UI и сервисами в порядке
		- &#10060; сообщения все равно могут слаться рассинхронизированно, что жрет много трафика, что критично для мобильной сети
		- &#10060; для получения всей информации надо общаться с несколькими сервисами, т.е. происходит интенсивное использование сети
		- &#10060; в случае появления виджета, которому необходимы данные нескольких сервисов снова увеличивается **coupling**		
	* **API Gateway**, что по сути является **фасадом** ко всем сервисам. 
		- &#9989; сервисы и UI независимы друг от друга и развязаны через Gateway
		- &#9989; данные из разныих сервисов могут быть получены UI одном запросом к фасаду, который уже сам знает какие сервисы ему запросить
		- &#10060; при изменении одного сервиса меняется фасад
		- &#10060; фасад может разрастись до огромных размеров и его будет тяжело поддерживать, особенно если учитывать разные виды UI (mobile, web, admin panel) которые могут иметь потребности в разных сервисах, но в итоге объединенный одним фасадом
	
	* Альтернативой, поддерживаемой автором, является **Гибридный подход**, где каждый вид UI (mobile, web, admin panel) имеет свой **API Gateway** (backend-for-frontends)
		- &#9989; сервисы и UI независимы друг от друга и развязаны через Gateway
		- &#9989; разные виды UI независимы друг от друга и от сервисов
		- &#9989; данные из разныих сервисов могут быть получены UI одном запросом к фасаду, который уже сам знает какие сервисы ему запросить
		- &#9989; меньше шансов, что фасад разрастется до огромных размеров
		- &#9989; при изменении одного сервиса меняется только зависимый фасад, если таковой есть
		- &#10060; необходимо поддерживать больше одного фасада
		- &#10060; возможно понадобится выделенная команда, с которой другим надо коммуницировать, что уменьшает независимость
		- &#10060; при изменении сервиса используемого в нескольких фасадах, их придется менять все

8. При необходимости использования какого-либо решения, как архитектор, нужно решить стоит ли это решение писать саммим или взять/купить готовое и внедрить. Опасность готовых решений может быть в том, что оно не полностью подходит и его надо кастомизировать под себя, что бывает не так просто и может дорого стоить и, возможно, проще что-то переделать у себя, чтобы это решение начало работать "из коробки" либо все же написать самим что-то, что не такое громоздкое и гибкое для кастомизации, но подходит идеально под нужды проекта.

9. **Prefer Choreography (event-based communication) over Orchestration (existing of some broker which redirects calls from one microservice to another and knows about all microservices)**

### Политика работы с базами данных в Микросервисной архитектуре

1. Избегать **foreign keys** в базах и соединять данные в коде сервисов, поскольку это соединение является частью бизнес-логики. Таком образом, мы избавляемся от лишнего **coupling** внутри базы данных. Недостатком данного подхода является увеличение количества обращений к базе.

2. Для того, чтобы один сервис не тянул данные из разных таблиц, о которых по логике ему не положено знать, модно сделать API call к другому сервису, которые оперирует данными из другой таблицы. Но в случае этого call'a не тащить **все** данные, а только **нужные**. Проблемой здесь является то, что теперь все **consistency checks** ложатся на плечи сервисов.

3. **Shared Static data** желательно тоже не хранить в общей таблице, а продублировать эти данные для каждого сервиса, или вообще положить их как часть кода каждого сервиса или выделить в отдельный сервис, если существует сложная бизнес-логика связанная с этими данными. Все ради уменьшения **coupling**, даже дублирование данных (х.з., стоит ли оно того).

4. **Shared Dynamic data**, например **Customer data**, которые могут быть нужны нескольким сервисам (Order, Discount, Delivery etc.) возможно стоит выделить в отдельный **Customer service** и обращаться к нему из разных сервисов, а он сам по себе будет уже управлять данными о **Customers**.

5. **Shared tables**, случай похожий на предыдущий, но в выделении отдельного сервиса нет смысла, так как не проглядыватся bounded context или какой-то сложной логики работы с данной таблицей. Тогда, можно саму таблицу разбить на столько частей, сколько сервисов ее использует и записать в каждую из новых таблиц только те данные, которые нужны конкретному сервису.

6. Книга **Refactoring Databases by Scott J Amber** в помощь

7. При рефакторинге монолитной архитектуры в микросервисную надо разбивать базу и выделяит сервисы **поэтапно**, тестируя изменения на каждом этапе.

8. При существовании множества сервисов обращающихся к базе появляется понятие **distributed transaction** и **eventual consistency**. Есть разные способы для работы в такой парадигме
	- **compensating transaction** - если одна из частей транзакции провалилась (вставка в данных разные таблицы разными сервисами в рамках одной бизнес-операции), то запускается механизм отката уже свершившихся частей транзакции. Проблема здесь в том, что **compensating transaction** тоже может провалиться, тогда нужен какой-то **retry** или **clean up/reconciliation**  по расписанию, но менеджить транзакции состоящие из 3-х, 4-х, 5-ти... частей все равно становиться слишком сложно.
	- **two-phase commit**. С этим подходом сначала идет **voting phase**, где каждый учасник транзакции (называемый _cohort_) говорит **transaction manager**, что он готов к обработке транзакции. Каждый учасник должен сказать _yes_, тогда **transaction manager** сообщает всем учасникам, что они могут выполниьт свои часть транзакции, а в случае хотя бы одного _no_ вся транзакция не выполняется. Здесь все равно есть риск, что какой-то участник провалит свою часть транзакции даже после того как он отправил _yes_, поэтому действует предположение, что после _yes_ транзакция выполнится в любом случае. Кроме того, присутствует _bottleneck_ в виде **transaction manager** от которго все зависят. Процесс координирования также означает наличие **lock'ов** на данных пока идет транзакция, что в случае **outage** влияет на всю систему и плохо для масштабирования.
	- в итоге, если часть системы нуждается в **реальной постоянной согласованности**, возможно, ее не стоит биь на части в виде микросервисов и отдельных вызовов к базе. Тогда транзакции можно отдать на откуп базе данных, в чем она хороша. Иначе же, можно обойтись **eventual consistency**.
	
9. В части **REPORTING** (примерно стр. 174) дается несколько советов о том, как можно организовать **reporting** часть системы. Здесь описывать все нет смысла, лучше обратиться к первоисточнику.

### Deployment и CI/CD в мире микросервисов

1. Желательно делать билды для каждого микросервиса отдельно и ребилдить только тот микросервис, который был изменен а не всю экосистему сервисов. Исключением является случай, когда разработка новой системы или рефакторинг монолита в микросервисы только начинается и границы сервисов и их API еще не определены, поэтому имеет смысл бандлить все **пока** как один солюшн и один билд.

2. **Build pipeline** - это концепция поэтапной сборки, интергрирования и развертывания приложения. В случае проблем на каком-то из этапов нет необходимости начинать следующий этап. **Build pipeline** дает возможность отслеживать прогресс изменений software и контролировать его качество. Релиз процесс как **build pipeline:**

_Compile and fast tests_ -> _Slow tests_ -> _UAT_ -> _Performance tests_ -> _Production_

3. **Continuous delivery (CD)** построено на концепции **Build pipeline** и является подходом, при котором мы получаем постоянный feedback о готовности к production release для каждого коммита и трактуем каждый коммит как release-кандидат.

4. Варианты хостинга сервисов
	- Multiple services per host
	- Application container with multiple services inside per single host
	- Single service per host
	- PaaS

5. **Автоматизация** - ключ к простоте управления (handling) множеством сервисов. Перед переходом с монолита на микросервисы прежде всего необходимо автоматизировать процессы сборки, развертывания и мониторинга, а после уже рефакторить и переделывать систему.

9. В части **From Physical to Virtual** (примерно стр. 217) говорится о **контейнеризации** и **виртуализации**, упоминаются несколько полезных инструментов, в том числе и Docker.

10. **SUMMARY**
	- Focus on maintaining the ability to release one service independently from another, and make sure that whatever technology you select supports this.
	- Author suggests to have a single repository per microservice and one CI build per microservice for deploying them separately.
	- Have single-service-per-host/container (use Docker or LXC to make managing the moving parts cheaper and easier)
	- Automate everything, if choosen technology does not allow automation, choose another technology, because **automation is a KEY to easy manageability**
	- Going deeper into this topic read the book by Jez Humble and David Farley "Continuous Delivery" 

### Тестирование микросервисов

1. Brian Marick's testing quadrant:

![Brian Marick's testing quadrant](https://lisacrispin.com/wp-content/uploads/2011/11/Agile-Testing-Quadrants.png)

2. Mike Cohn's test pyramid

![Mike Cohn's test pyramid](https://martinfowler.com/articles/practical-test-pyramid/testPyramid.png)

3. **Unit tests** - это **small-scoped** тесты и их главная цель дать **быстрый** _feedback_ о том насколько хорошо написанная функциональность работает.

4. **Service tests** - тестируют возможности и функциональность отдельного сервиса. Можно сказать, это **middle-scoped** тесты, они могут быть быстрыми как unit, так и долго выыполняющимися при, например, интеграции с реальной базой или другими сервисами.

5. **End-to-end tests (UI in Mike Cohn's test pyramid)** - тесты для всей системы в целом. Это **large-scoped** тесты. Когда они успешно выполняются можно быть более-менее уверенным, что система работает (при условии, что тесты написаны корректно).

6. Чем больше **testing scope** тем медленней тесты работают и долшье ждать feedback. Однако чем более изолированней тесты (меньше scope) тем меньше информации о том как система себя поведет в целом.

7. Следуя принципу **Fail fast** в build pipeline необходимо настраивать тестовый прогон в порядке увеличения **testing scope**, т.е. сначала unit, потом service, а потом end-to-end тесты.

8. Есть несколько проблем с **large-scoped** тестами:
	- В случае с интеграционными тестами (service tests) или end-to-end тестами, какие версии других сервисов (от которых зависит наш тестируемый) брать для тестирования? Продакшн версии или последнии из UAT?
	- При наличии в активной разработке нескольких сервисов, как ранить end-to-end тесты и трактовать их результаты, если несколько сервисов были изменены?

Эти проблемы можно решить наличием нескольких веток build pipeline'ов с unit и service тестами, которые при положительном результате каждой ветки объединиются и ранять общие для всех end-to-end tests.

Еще одной проблемой end-to-end тестов в случае, когда есть несколько команд и каждая отвечает за свой сервис, является то, что не очевидно, кто должен реагировать, если они упали. Решением может быть дежурства каждой команды, по-спринтово, например.

9. **Test Journeys, Not Stories**. Это значит, что не надо добавлять на каждую user-story по end-to-end тесту, поскольку они обычно долго ранятся и управлять ими и их зависимостями сложно, то в end-to-end лучше добавлять тесты, которые проверяют **core** логику системы, а user-story лучше проверять в service тестах в изоляции. **Core логика** - это например, flow заказа в онлайн магазине, начиная от UI и заканчивая доставкой и оплатой и все это один end-to-end тест, который должен работать всегда, независимо от изменений в сервисах.

10. **Consumer-driven contract (CDC)** - это концепция тестирования сервиса с точки зрения _потребителя_ этого сервиса. На пирамиде Mike Cohn'a эти тесты находятся рядом с service тестами, така тестируют конкретный сервис. Преимущество данных тестов перед обычными интеграционными в том, что они тестируют конкретный реальный сценарий. Кроме того, они могут тестировать **разную** функциональность одного и того же сервиса, но с точки зрения **разных** потребителей. Например, у нас есть _Customer_ сервис, отвечающий за клиентов. У данного сервиса 2 потребителя: _Customer helpdesk_ service и _Delivery_ service. Оба сервиса имеют свои ожидания (expectations) о том, как _Customer_ сервис должен работать. Соответственно создаются два набора **CDC** тестов для каждого аспекта работы _Customer_ сервиса. Хорошей практикой является создание этих тестов в коллаборации между командами _Customer_ и _Customer helpdesk_ сервисов и _Customer_ и _Delivery_ сервисов. Преимущество данных тестов в том, что в случае проблем с тестом, сразу видно какой _потребитель_ заимпакчен. Pact: [link to Pact!](https://github.com/pact-foundation/pact.io) - инструмент для **CDC** тестов.

11. Автор советует предпочесть **CDC** и заменить ими end-to-end тесты, исходя из его опыта и опыта его знакомых, это работает, при этом **CDC** требуют меньше времени для работы, так как имеют меньший _scope_, и более информативны в определении проблемных мест.

12. **TESTING AFTER PRODUCTION**. Не всегда testing environment полностью повторяет production, соответственно во время релиза возникает необходимость протестировать сервисы уже после релиза на production environment'е. Несколько вариантов реализации такого тестирования:
	- _smoke test suite_ - небольшой набор тестов, который прогоняется после релиза и направлен на то, чтобы протестировать места где environment различается между UAT и Production.
	- _blue/green deployment_ - с этим подходом мы имеем 2 копии системы развернутых одновременно, но только одна получает реальные requests. Т.о. старая версия пока работает, а с новой версией прогоняются _smoke tests_. Если тесты в порядке, то мы переключаем систему со старой версии на новую.
	- _canary releasing_ - чем-то схож с _blue/green deployment_, но смысл в том, что мы **постепенно** переключаем proudction со старой версии на новую, когда обе развернуты на production. Каждый раз, переключая какую-то часть системы сос старой на новую, мы проверяем, что она справляется с нагрузкой и функционально ведет себя правильно. На каждом этапе, в случае каких-либо проблем, мы имеем возможность откатить систему. С таким подходом можно также копировать запросы, которые идут к старой production системе, в новую и сравнивать как они себя ведут. Netflix использует _canary releasing_.
	
13. 
