## Good practices for high-performance and scalable applications (Node.js example)

 - https://medium.com/iquii/good-practices-for-high-performance-and-scalable-node-js-applications-part-1-3-bb06b6204197
 - https://medium.com/iquii/good-practices-for-high-performance-and-scalable-node-js-applications-part-2-3-2a68f875ce79
 - https://medium.com/iquii/good-practices-for-high-performance-and-scalable-node-js-applications-part-3-3-c1a3381e1382

### Варианты горизонтального масштабирования приложения:

1. Множество процессов на одной машине (каждый процесс - это экземпляр нашего сервиса). При такой архитектуте необходимо выделить **master**-процесс и **worker**-процессы для каждого ядра. **Master**-процесс используя round-robin механизм распределяет нагрузку и входящие запросы между **worker**-процессами. С точки зрения кода, это все будет один и тот же сервис с неким if-ом, по которому собственно и определяем режим работы данного экземпляра (master или worker).

2. Все тоже самое, что и в первом случае, но используя **third-party process manager** как **master**. Для Node.js, например, это **PM2**.

3. Множество машин с сетевым **load balancing**. Согласно архитектуре, имеем несколько машин, на которых установлены несколько экземпляров нашего сервиса, то есть каждая машина представляет собой пункты 1 или 2. Балансировщик между машинами можно использовать какой-нибудь уже готовый (например, Elastic Load Balancer в AWS). Можно добавить несколько балансеров и распределять трафик между ними через DNS Resolver.

### Как сделать сервис готовым для масштабирования:

1. Необходимо разворачивать экземпляры приложения и базы данных (включая in-memory caches типа Redis) на отдельных машинах, чтобы их можно было масштабировать отдельно друг от друга.

2. Сервисы должны быть **stateless**, так как их несколько экземпляров и к какому конкретно попадет один и тот же пользователь между разными запросами - неизвестно. Конфигурации и настройки, которые могут измениться во время работы приложения, надо хранить во внешнем хранилище (база, файловая система или Redis-like база), чтобы все экземпляры могла подхватить эти изменения.

3. Аутентификация и авторизация требует хранения информации о том, что текущий пользователь залогинен и авторизован на всех экземплярах приложения, но при этом он не должен вводить свои credentials каждый раз, когда балансер переключается между экземплярами приложения. Варианты решения данной проблемы:

- Настроить Load balancer всегда перенаправлять запросы от одного и того же пользователя на один и тот же сервис. Но это довольно сложно менеджить и частичто убивает независимость сервисов и масштабирование.
- Хранить данные сессии в базе или на файле, но множественные I/O операции плохо влияют на производительность.
- Немоного проще и производительнее хранить данные в кэше типа Redis, но требует больше оперативной памяти
- Использовать JWT токены - JSON Web Tokens, хранить их на клиенте в куках и пересылать их при каждом запросе на сервер, а сам сервер уже может их процессить и проверять является ли данный токен настоящим и аутентифицирован ли пользователь. Т.к. JWT не зашифрован и просто хранится в base64, то для их передачи необходимо использовать SSL канал. 

4. Хранить user=-generated assets не в файловой системе, посколько они будут доступны только на одной машине, а в каком-то специализированном сервисе, типа S3 от Amazon и сохранять в базу только URI для этих ресурсов. Все экземпляры приложения смогут получить эти URI из базы и сами ресурсы по URI.

5. Для real-time общения между сервером и клиентом или между клиентами использовать WebSocketsа, а Redis для pub-sub функциональностии и как медиатор между экземплярами пролижения. Long-polling не подойдет поскольку требует постоянной сессии, от чего мы пытаемся уйти.

## Мысли и советы из книги Sam Newman "Building Microservices"

1. **Bounded context** из DDD отлично описывает один микросервис. Если определить все главные **bounded contexts**, то можно каждый выделить в сервис, а каждый сервис может содержать свои внутренние **bounded contexts**.

2. Систему можно начинать проектировать и делать как монолитную в одном солюшне для того чтобы постепенно проявить все внутренние (использующиеся внутри сервиса) и внешние (использующиеся для передачи данных между сервисами) **модели** и **bounded contexts**. Затем, когда все проясниться и устаканиться, можно ее (систему) разбить на микросервисы. **Это совет для новичков**. С опытом систему можно сразу проектировать как микросервисную.

3. При проектировании микросервисов необходимо думать в **контексте возможностей (capabilities)** проектируемого сервиса и того **что он умеет делать**, а не данных которыми он оперирует, иначе выйдет просто CRUD вокруг которого строится сервис. А когда эти возмоности и способности определены - уже можно выделять данные и модели, которые нужны для реализации этих спосбностей.

4. Вариант общения клиента и сервера: гуглить **Richardson Maturity Model и Hypermedia Controls (HATEOAS)**. Фаулер об этом писал, подход прикольный, но походу не получил популярность.

5. Микросервисы должны иметь **low coupling** между друг другом и **high cohesion** внутри себя, что логично. Но **shared** между сервисами база данных или **библиотека с data types** для всех сервисов в итоге неявно увеличивает **coupling**. Кроме того, создание библиотеки клиента для сервиса и использование ее в разных клиентах этого сервиса тоже создает **coupling** между **ВСЕМИ** клиентами и сервисом. Принцип **DRY** тоже можно и нужно нарушать в угоду независимости сервисов друг от друга. Лучше скопипастить какой-то кусок кода с бизнес логикой чем выделять его в библиотеку и шарить ее между сервисами (речь не идет вспомогательных библиотеках типа log4net).

6. Согласно автору **асинхронная event-based** коммуникация между микросервисами через **message broker** типа Rabbit MQ является лучшим вариантом реализации архитектуры микросервисов, так как имеет наименьший **coupling** и микросервисы не знают друг о друге.

7. UI layer за которым стоит множество микросервисов может общаться с ними следующим образом:
	* UI компонент, который шлет запросы всем необходимым сервисам
		- &#9989; SRP - UI сам за себя отвечает и знает что ему нужно
		- &#10060; сообщения могут слаться рассинхронизированно, что жрет много трафика, что критично для мобильной сети
		- &#10060; для получения всей информации надо общаться с несколькими сервисами, т.е. происходит интенсивное использование сети
		- &#10060; скорее всего понадобиться выделенная команда для поддержи UI, а это значит необходима коммуникация между командами, теряется независимость
		- &#10060; увеличиватся **coupling** между сервисами и UI
	
	* Каждый сервис представляет свой UI виджет. Все они собираются в некий box и показываются пользователю.  
		- &#9989; UI каждого сервиса сапортится командой этого сервиса и нет нужды в выделенной UI команде
		- &#9989; **coupling** между UI и сервисами в порядке
		- &#10060; сообщения все равно могут слаться рассинхронизированно, что жрет много трафика, что критично для мобильной сети
		- &#10060; для получения всей информации надо общаться с несколькими сервисами, т.е. происходит интенсивное использование сети
		- &#10060; в случае появления виджета, которому необходимы данные нескольких сервисов снова увеличивается **coupling**		
	* **API Gateway**, что по сути является **фасадом** ко всем сервисам. 
		- &#9989; сервисы и UI независимы друг от друга и развязаны через Gateway
		- &#9989; данные из разныих сервисов могут быть получены UI одном запросом к фасаду, который уже сам знает какие сервисы ему запросить
		- &#10060; при изменении одного сервиса меняется фасад
		- &#10060; фасад может разрастись до огромных размеров и его будет тяжело поддерживать, особенно если учитывать разные виды UI (mobile, web, admin panel) которые могут иметь потребности в разных сервисах, но в итоге объединенный одним фасадом
	
	* Альтернативой, поддерживаемой автором, является **Гибридный подход**, где каждый вид UI (mobile, web, admin panel) имеет свой **API Gateway** (backend-for-frontends)
		- &#9989; сервисы и UI независимы друг от друга и развязаны через Gateway
		- &#9989; разные виды UI независимы друг от друга и от сервисов
		- &#9989; данные из разныих сервисов могут быть получены UI одном запросом к фасаду, который уже сам знает какие сервисы ему запросить
		- &#9989; меньше шансов, что фасад разрастется до огромных размеров
		- &#9989; при изменении одного сервиса меняется только зависимый фасад, если таковой есть
		- &#10060; необходимо поддерживать больше одного фасада
		- &#10060; возможно понадобится выделенная команда, с которой другим надо коммуницировать, что уменьшает независимость
		- &#10060; при изменении сервиса используемого в нескольких фасадах, их придется менять все

8. При необходимости использования какого-либо решения, как архитектор, нужно решить стоит ли это решение писать саммим или взять/купить готовое и внедрить. Опасность готовых решений может быть в том, что оно не полностью подходит и его надо кастомизировать под себя, что бывает не так просто и может дорого стоить и, возможно, проще что-то переделать у себя, чтобы это решение начало работать "из коробки" либо все же написать самим что-то, что не такое громоздкое и гибкое для кастомизации, но подходит идеально под нужды проекта.

9. **Prefer Choreography (event-based communication) over Orchestration (existing of some broker which redirects calls from one microservice to another and knows about all microservices)**

### Политика работы с базами данных в Микросервисной архитектуре

1. Избегать **foreign keys** в базах и соединять данные в коде сервисов, поскольку это соединение является частью бизнес-логики. Таком образом, мы избавляемся от лишнего **coupling** внутри базы данных. Недостатком данного подхода является увеличение количества обращений к базе.

2. Для того, чтобы один сервис не тянул данные из разных таблиц, о которых по логике ему не положено знать, модно сделать API call к другому сервису, которые оперирует данными из другой таблицы. Но в случае этого call'a не тащить **все** данные, а только **нужные**. Проблемой здесь является то, что теперь все **consistency checks** ложатся на плечи сервисов.

3. **Shared Static data** желательно тоже не хранить в общей таблице, а продублировать эти данные для каждого сервиса, или вообще положить их как часть кода каждого сервиса или выделить в отдельный сервис, если существует сложная бизнес-логика связанная с этими данными. Все ради уменьшения **coupling**, даже дублирование данных (х.з., стоит ли оно того).

4. **Shared Dynamic data**, например **Customer data**, которые могут быть нужны нескольким сервисам (Order, Discount, Delivery etc.) возможно стоит выделить в отдельный **Customer service** и обращаться к нему из разных сервисов, а он сам по себе будет уже управлять данными о **Customers**.

5. **Shared tables**, случай похожий на предыдущий, но в выделении отдельного сервиса нет смысла, так как не проглядыватся bounded context или какой-то сложной логики работы с данной таблицей. Тогда, можно саму таблицу разбить на столько частей, сколько сервисов ее использует и записать в каждую из новых таблиц только те данные, которые нужны конкретному сервису.

6. Книга **Refactoring Databases by Scott J Amber** в помощь

7. При рефакторинге монолитной архитектуры в микросервисную надо разбивать базу и выделяит сервисы **поэтапно**, тестируя изменения на каждом этапе.

8. При существовании множества сервисов обращающихся к базе появляется понятие **distributed transaction** и **eventual consistency**. Есть разные способы для работы в такой парадигме
	- **compensating transaction** - если одна из частей транзакции провалилась (вставка в данных разные таблицы разными сервисами в рамках одной бизнес-операции), то запускается механизм отката уже свершившихся частей транзакции. Проблема здесь в том, что **compensating transaction** тоже может провалиться, тогда нужен какой-то **retry** или **clean up/reconciliation**  по расписанию, но менеджить транзакции состоящие из 3-х, 4-х, 5-ти... частей все равно становиться слишком сложно.
	- **two-phase commit**. С этим подходом сначала идет **voting phase**, где каждый учасник транзакции (называемый _cohort_) говорит **transaction manager**, что он готов к обработке транзакции. Каждый учасник должен сказать _yes_, тогда **transaction manager** сообщает всем учасникам, что они могут выполниьт свои часть транзакции, а в случае хотя бы одного _no_ вся транзакция не выполняется. Здесь все равно есть риск, что какой-то участник провалит свою часть транзакции даже после того как он отправил _yes_, поэтому действует предположение, что после _yes_ транзакция выполнится в любом случае. Кроме того, присутствует _bottleneck_ в виде **transaction manager** от которго все зависят. Процесс координирования также означает наличие **lock'ов** на данных пока идет транзакция, что в случае **outage** влияет на всю систему и плохо для масштабирования.
	- в итоге, если часть системы нуждается в **реальной постоянной согласованности**, возможно, ее не стоит биь на части в виде микросервисов и отдельных вызовов к базе. Тогда транзакции можно отдать на откуп базе данных, в чем она хороша. Иначе же, можно обойтись **eventual consistency**.
	
9. В части **REPORTING** (примерно стр. 174) дается несколько советов о том, как можно организовать **reporting** часть системы. Здесь описывать все нет смысла, лучше обратиться к первоисточнику.

### Deployment и CI/CD в мире микросервисов

1. Желательно делать билды для каждого микросервиса отдельно и ребилдить только тот микросервис, который был изменен а не всю экосистему сервисов. Исключением является случай, когда разработка новой системы или рефакторинг монолита в микросервисы только начинается и границы сервисов и их API еще не определены, поэтому имеет смысл бандлить все **пока** как один солюшн и один билд.

2. **Build pipeline** - это концепция поэтапной сборки, интергрирования и развертывания приложения. В случае проблем на каком-то из этапов нет необходимости начинать следующий этап. **Build pipeline** дает возможность отслеживать прогресс изменений software и контролировать его качество. Релиз процесс как **build pipeline:**

_Compile and fast tests_ -> _Slow tests_ -> _UAT_ -> _Performance tests_ -> _Production_

3. **Continuous delivery (CD)** построено на концепции **Build pipeline** и является подходом, при котором мы получаем постоянный feedback о готовности к production release для каждого коммита и трактуем каждый коммит как release-кандидат.

4. Варианты хостинга сервисов
	- Multiple services per host
	- Application container with multiple services inside per single host
	- Single service per host
	- PaaS

5. **Автоматизация** - ключ к простоте управления (handling) множеством сервисов. Перед переходом с монолита на микросервисы прежде всего необходимо автоматизировать процессы сборки, развертывания и мониторинга, а после уже рефакторить и переделывать систему.

9. В части **From Physical to Virtual** (примерно стр. 217) говорится о **контейнеризации** и **виртуализации**, упоминаются несколько полезных инструментов, в том числе и Docker.

10. **SUMMARY**
	- Focus on maintaining the ability to release one service independently from another, and make sure that whatever technology you select supports this.
	- Author suggests to have a single repository per microservice and one CI build per microservice for deploying them separately.
	- Have single-service-per-host/container (use Docker or LXC to make managing the moving parts cheaper and easier)
	- Automate everything, if choosen technology does not allow automation, choose another technology, because **automation is a KEY to easy manageability**
	- Going deeper into this topic read the book by Jez Humble and David Farley "Continuous Delivery" 

### Тестирование микросервисов

1. Brian Marick's testing quadrant:

![Brian Marick's testing quadrant](https://lisacrispin.com/wp-content/uploads/2011/11/Agile-Testing-Quadrants.png)

2. Mike Cohn's test pyramid

![Mike Cohn's test pyramid](https://martinfowler.com/articles/practical-test-pyramid/testPyramid.png)

3. **Unit tests** - это **small-scoped** тесты и их главная цель дать **быстрый** _feedback_ о том насколько хорошо написанная функциональность работает.

4. **Service tests** - тестируют возможности и функциональность отдельного сервиса. Можно сказать, это **middle-scoped** тесты, они могут быть быстрыми как unit, так и долго выыполняющимися при, например, интеграции с реальной базой или другими сервисами.

5. **End-to-end tests (UI in Mike Cohn's test pyramid)** - тесты для всей системы в целом. Это **large-scoped** тесты. Когда они успешно выполняются можно быть более-менее уверенным, что система работает (при условии, что тесты написаны корректно).

6. Чем больше **testing scope** тем медленней тесты работают и долшье ждать feedback. Однако чем более изолированней тесты (меньше scope) тем меньше информации о том как система себя поведет в целом.

7. Следуя принципу **Fail fast** в build pipeline необходимо настраивать тестовый прогон в порядке увеличения **testing scope**, т.е. сначала unit, потом service, а потом end-to-end тесты.

8. Есть несколько проблем с **large-scoped** тестами:
	- В случае с интеграционными тестами (service tests) или end-to-end тестами, какие версии других сервисов (от которых зависит наш тестируемый) брать для тестирования? Продакшн версии или последнии из UAT?
	- При наличии в активной разработке нескольких сервисов, как ранить end-to-end тесты и трактовать их результаты, если несколько сервисов были изменены?

Эти проблемы можно решить наличием нескольких веток build pipeline'ов с unit и service тестами, которые при положительном результате каждой ветки объединиются и ранять общие для всех end-to-end tests.

Еще одной проблемой end-to-end тестов в случае, когда есть несколько команд и каждая отвечает за свой сервис, является то, что не очевидно, кто должен реагировать, если они упали. Решением может быть дежурства каждой команды, по-спринтово, например.

9. **Test Journeys, Not Stories**. Это значит, что не надо добавлять на каждую user-story по end-to-end тесту, поскольку они обычно долго ранятся и управлять ими и их зависимостями сложно, то в end-to-end лучше добавлять тесты, которые проверяют **core** логику системы, а user-story лучше проверять в service тестах в изоляции. **Core логика** - это например, flow заказа в онлайн магазине, начиная от UI и заканчивая доставкой и оплатой и все это один end-to-end тест, который должен работать всегда, независимо от изменений в сервисах.

10. **Consumer-driven contract (CDC)** - это концепция тестирования сервиса с точки зрения _потребителя_ этого сервиса. На пирамиде Mike Cohn'a эти тесты находятся рядом с service тестами, так как тестируют конкретный сервис. Преимущество данных тестов перед обычными интеграционными в том, что они тестируют конкретный реальный сценарий. Кроме того, они могут тестировать **разную** функциональность одного и того же сервиса, но с точки зрения **разных** потребителей. Например, у нас есть _Customer_ сервис, отвечающий за клиентов. У данного сервиса 2 потребителя: _Customer helpdesk_ service и _Delivery_ service. Оба сервиса имеют свои ожидания (expectations) о том, как _Customer_ сервис должен работать. Соответственно создаются два набора **CDC** тестов для каждого аспекта работы _Customer_ сервиса. Хорошей практикой является создание этих тестов в коллаборации между командами _Customer_ и _Customer helpdesk_ сервисов и _Customer_ и _Delivery_ сервисов. Преимущество данных тестов в том, что в случае проблем с тестом, сразу видно какой _потребитель_ заимпакчен. Pact: [link to Pact!](https://github.com/pact-foundation/pact.io) - инструмент для **CDC** тестов.

11. Автор советует предпочесть **CDC** и заменить ими end-to-end тесты, исходя из его опыта и опыта его знакомых, это работает, при этом **CDC** требуют меньше времени для работы, так как имеют меньший _scope_, и более информативны в определении проблемных мест.

12. **TESTING AFTER PRODUCTION**. Не всегда testing environment полностью повторяет production, соответственно во время релиза возникает необходимость протестировать сервисы уже после релиза на production environment'е. Несколько вариантов реализации такого тестирования:
	- _smoke test suite_ - небольшой набор тестов, который прогоняется после релиза и направлен на то, чтобы протестировать места где environment различается между UAT и Production.
	- _blue/green deployment_ - с этим подходом мы имеем 2 копии системы развернутых одновременно, но только одна получает реальные requests. Т.о. старая версия пока работает, а с новой версией прогоняются _smoke tests_. Если тесты в порядке, то мы переключаем систему со старой версии на новую.
	- _canary releasing_ - чем-то схож с _blue/green deployment_, но смысл в том, что мы **постепенно** переключаем proudction со старой версии на новую, когда обе развернуты на production. Каждый раз, переключая какую-то часть системы сос старой на новую, мы проверяем, что она справляется с нагрузкой и функционально ведет себя правильно. На каждом этапе, в случае каких-либо проблем, мы имеем возможность откатить систему. С таким подходом можно также копировать запросы, которые идут к старой production системе, в новую и сравнивать как они себя ведут. Netflix использует _canary releasing_.
	
13. Нужно учитывать, что какими бы не были отличными тесты и какое бы покрытие не было бы достигнуто - от всех проблем не удастся избавиться и они однажды проявятся на проде. Здесь в игру вступает **Mean Time to Repair (MRTR) vs Mean Time Between Failures (MTBF)**. Необходимо искать компромисс между этими характеристиками системы и иметь большой MTBF (что обеспечивается хорошими тестами), но и иметь адекватный MRTR и быть готовым ко сбоям в системе, то есть иметь некую стратегию на случай отказа системы.

14. Большой объем тестов кроется под термином **nonfunctional tests**, которые автор предпочитает называть **cross-functional tests**, поскольку они охватывают различные аспекты системы (performance, UI validity in terms of HTML, HTML accessability for disabled people, scalability, etc.) Такие тесты обычно возможно провести только на проде в реальных условиях, но во время разработки и тестирования, по крайней мере, можно разработать стретегии тестирования и трекать, движемся ли мы в правильном направлении. С учетом широкого охвата различных аспектов системы данными тестами, их можно и нужно приоритезировать и учитывать, так как часто надежность и доступность одного аспекта системы важнее другого, например надежность платежного сервиса явно важнее чем произодительность рекомендательного. Автор советует учитывать данные тесты с ранних стадий разработки, а не откладывать их на потом.

15. **Performance Tests**. Пожалуй, в мире микросервисов, Performance Tests еще важнее чем в Монолите, поскольку теперь появляются множество акторов, которые взаимодействуют между собой по сети, каждый из них может обращаться к базам данных, что увеличвает в целом количество IO операций по сравнению с Монолитом. Данные тесты практически бесполезны в изоляции, поэтому часто из откладывают на потом, но автор советует покрывать ими Core части системы и основные Journes, даже когда вся система еще не написана. Понятно, что данный тип тестов требует prod-like окружения и объемов данных, сами тесты могут выполняться долго, поэтому хорошей практикой является прогон некоторого подмоножества тестов каждый день и основного множества раз в неделю. **Важным также является определить цели (targets) этих тестов, то есть числа производительности, по которым можно понять, что тест прошел или упал.** Иначе есть шанс, что на результаты никто не будет обращать внимания.

### Monitoring

**Monitor the small things, and use aggregation tosee the bigger picture**.

Logging is a key to proper monitoring. Some tools mentioned by author:
- **Kibana** is an ElasticSearch-backed system for viewing logs
- **Graphite** is an system for storing, querying and viewing metrics. It allows view aggregated metrics for the whole system (e.g. CPU load), aggregated metrics for all instances if concrete service or just concrete instance of concrete service.

Автор рекомендует, чтобы сервисы свои базовые выставляли наружу сами по себе. Это облегчит мониторинг для внешних инструментов и даст понимание какие фичи данныъ сервисов используются чаще, чем другие. Например, Customer service может выдавать метрику о том, сколько покупателей и как часто смотрят на свои предыдущие заказы. Это полезно знать, например, для того нужно ли дальше поддерживать фичу или стоит ее как-то улучшить или оптимизировать.

**Synthetic transaction** - транзация, которая запускает в цепь событий и калькуляций в системе имитирующих реальные события и калькуляции. **Semantic monitoring** - техника, с использованием **Synthetic transaction**, собиранием метрик на основе данной транзации и последующая оценка данных метрик.

В микросервисной архитектуре множество сервисов общаются между собой, что приводит к сложной цепочки вызовов. Если на каком-то этапе произойдет ошибка, будет трудно отследить в логах какой именно вызов привел к ней, так как сервисы обрабатываебт множество вызовов одновременно. Для целей отслеживания всей цепи вызовов инициированной конкретным вызовом автор рекмендует использовать **Correlation ID** - механизм, с помощью которого можно отслеживать цепочку вызовов-ответов между различными сервисами. Инициирующий некую служную (требующую участия множества сервисов) операцию сервис генерирует уникальный **Correlation ID** и пробрасывает его дальше в вызовах, последующие сервисы, видя наличие ID, тоже пробрасываеют его дальше и логируют. Т.о. можно отследить в логах конкретный реквест.

Track the health of all downstream responses, at a bare minimum including theresponse time of downstream calls, and at best tracking error rates. Libraries likeHystrix can help here.

Автор советует иметь некую стандартизацию в логах сервисов, для того чтобы было проще аггрегировать информацию. Например, один сервис может писать ResponseTime в логах, а другой RspTimeSecs, хотя эти данные значат одно и тоже. Вот для этого и нужно стандартизировать внутри команд такие core вещи.

Книга этого же автора про мониторинг: [https://www.oreilly.com/webops-perf/free/lightweight-systems.csp]

### Security

Монолит сам обрабатыват и содержит логику аутентификации и авторизации. В случае микросервисов такой подход не работает, поскольку мы не хотим чтобы пользователь логинился в каждый микросервис учавствующий в обработке его запроса. **Необходим SSO (Single Sign On)**

SAML (security assertion markup language) - старая реализация SSO.
OpenID Connect - замена SAML, новая реализация SSO

Одна из реализации данного подхода - это **SSO Gateway**. Пользователь делает вызов, который идет в **SSO Gateway**, тот в свою очередь перенаправляет его в **Identity Provider**, который аутентифицирует и аворизует данного пользователя и возвращает эти данные в **SSO Gateway**. Затем **SSO Gateway** вызывает уже непосредственно необходимый сервис с Principal info and Roles в HTTP заголовке. Т.о. все запросы к сервисам уже преаторизированы. Проблема данного подхода в том, что мы имеем **single point of failure**,  к тому в области безопасности. 

Автор рекомендует придерживаться принципа **defense in depth** — from network perimeter, to subnet, to firewall, to machine, to operating system, to the underlying hardware. Тогда аутентификацию можно доверить **SSO Gateway**, а без **defense in depth** получается, что "все яйца хранятся в одной корзине".

**_Роли авторизации рекумендуется создавать так, чтобы они повторяли структуру предприятия_**

#### Общение сервисов внутри сетевого периметра

Общение сервисов внутри сетевого периметра (т.е. внутри предприятия без участия интернета) можно не использовать аутентификацию. Но здесь есть опасность атаки man-in-the-middle, если кто-то пробьет сетевой барьер и вмешиается в запрос между сервисами. Поэтому совсем без security нельзя обойтись. Несколько вариантов защищенного общения между сервисами:

- использовать **Basic HTTP Auth** для общения между сервисами внутри периметра и шифровать трафик с помощью HTTPS внутри сети, т.к. парольи юзернейм не безопасно слать по обычному HTTP. Но здесь возникают трудности с выпуском и дальнейшим управением SSL сертификатами для работы по HTTPS. 
- использовать уже **существующую (если это так) инфраструктуру SAML или OpenID Connect**.
- можно использовать **клиентские сертификаты**, тогда это будет точно гарантировать, что клиент действитеьно тот, за кого себя выдает, но здесь проблема опять же с выпуском и дальнейшим управением SSL сертификатами, причем еще хуже чем в первом случае.
- **hash-based messaging code (HMAC)** - механизм работает так: генерится хеш на основе информции в запросе с помощью приватного ключа и хеш посылается вместе с запросом. На стороне сервера (который тоже хранит этот приватный ключ) опять генерим хеш и если он совпадет с пришедшим, значит информация верна. Проблема с этим подходом в том, что нужно как-то синхронизировать приватные ключи у клиента и сервера, если их переодически передавать, то снова необходим ОЧЕНЬ ЗАЩИЩЕННЫЙ механизм, если их хардкодить, то в случае компроментации их труднее будет заменить. Еще одна проблема в том, что сама информация в запросе доступна сниферам, они просто не смогут пометить в нее что-то свое.
- **API keys** - данный подход испоьзуют такие компании как Twitter, Google, Flickr, AWS для работы с их public API. С помощию данного механизма можно управлять не только доступом к ресурсу, но и ограничивать частоту использования и т.п. Вариантов реализации тоже множество, некоторые системы используют единый ключ и тогда подход стновится схожим с HMAC, некоторые используют пару публичный-приватный ключ, некоторые позволяют проложит мост между API ключем и Directory Service организации и таким образом сразу управлять доступом по роляим опираясь на информацию из Directory Service.

**The Deputy Problem** - проблема, при которой авторизованный пользователь может запросить данные, которые относятся к другому пользователю, используя сервис-посредник. Например, пользователь может узнать статус своего заказа в оналайн-магазине, для этого shopping service (сервис-посредник, который провел аутентификацию) обращается к order service (который без всякой аутентификации доверяет сервису-посреднику) и тот возвращает данные. Поскольку пользоваель авторизован, а для общения между сервисами **внутри периметра** может использоваться что угодно из перечисенных выше вариантов (API keys, HMAC, etc.) то нет никаких ограничений на то, чтобы отдать данному пользователю данные о чужом заказе. Данная проблема не имеет конкреного решения, поскольку она комплексная. Есть некоторые варианты из которых можно исходить в зависимости от чувствительности информации, которую так модно получить - неявное доверие, т.е. просто забить, проверка пользователя, который вызвал сервис и отклонение запроса в случае провала проверки или вообще редирект на ввод учетных данных запрашиваемого пользователя. _Необходимо знать что такая проблема существует_.

#### Защита хранимых данных

- Автор рекомендует шифровать хранимые данные, причем не писать свои велосипеды/алгоритмы шифрования, а использовать хорошо зарекомендовавшие себя решения.
- Пароли хешировать с солью
- Ключи для шифрования НЕ ХРАНИТЬ в той же базе, которую они шифруют, а использовать отдельное хранилище ключей или использовать встроенные возможности движка базы данных, если такие имеются
- Поскольку шифровка и дешифровка требуют вычислительных мощностей, необходимо решить какие данные действительно необходимо шифровать, а какие нет. Например, логи можно не шифровать, но тогда необходимо учитывать какую информацию туда писать.
- Автор рекомендует шифровать все данные как тоько они появятся и всегда иметь их зашифрованными, а дешифровать по требованию.
- Бекапы ТОЖЕ неоходимо ШИФРОВАТЬ, а не оставлять их так.

#### Defence in Depth

- Firewalls - genral and specific ones 
- Логирование - не защита, но хорошо агрегированные логи могут показать, что где-то что-то идет не так
- **Intrusion detection systems (IDS)** can monitor networks or hosts for suspicious behavior, reporting problems when it sees them. **Intrusion prevention systems (IPS)**, as well as monitoring for suspicious activity, can step in to stop it from happening.
- Network segregation
- DO NOT FORGET AND IGNORE patches for servers' OS.

**_Решение о методах защиты данных (насколько строго нужно обезопасить данные) должно приниматься исходя из природы и ценности информации, которую эти данные несут_**

**_Необходимо также думать о механизме отзыва прав доступа у бывших сотрудников, т.к. нет более знакомого с вашей системой человека чем озлобленный бывший сотрудник, который может причинить больше вреда чем внейшний злоумышленник_**

**_Золотым правилом является не изобретать колесо, т.е. не придумывать свои алгоритмы шифрования и протоколы безопасности_**

Некоторые термины и ссылки:
- OWASP - https://habr.com/ru/company/simplepay/blog/258499/
- Microsoft Security Development Lifecycle (SDL) - https://www.microsoft.com/en-us/securityengineering/sdl

### Conway's law (Закон Конвея)

**Любая организация, которая проектирует систему (в т.ч. информационную), неизбежно создаст проект, структура которого является копией коммуникационной структуры организации.** Это же можно выразить так, что если в вашей организации есть четыре команды по разработке некоего компилятора, то в итоге вы получите 4-х этапный компилятор.

В "Exploring the Duality Between Product and Organizational Architectures" (Harvard Business School) авторы Alan MacCormack, John Rusnak, и Carliss Baldwin рассматривают ряд различных программных систем, которые в общих чертах классифицируются как созданные либо _слабо связанными_, либо _тесно связанными_ организациями. 

_Тесно связанные_ организации (фирмы, выпускающие коммерческие продукты), как правило, имеют четкие цели и видение своего продукта, в то время как _слабосвязанные организации_ представлены распределенными сообществами работающими с открытым исходным кодом. 

В своем исследовании, в котором они сравнивали аналогичные пары продуктов из каждого типа организации, авторы обнаружили что более _слабосвязанные организации_ фактически создали более модульные, менее связанные системы, тогда как программное обеспечение _более узко сфокусированной (тесно связанной)_ организации было менее модульным.

**Amazon** осозна преимущества небольших команд, который автономны и полностью отвечают за жизненный цикл системы, которую они разрабатывают. Это привело к правилу 2-pizza teams, то есть команды такого размера, чтобы их модно было накормить 2-мя пиццами. Собственно, такая организция небольших команд ответственных за полный жизненный цикл систем и привела к созданию Amazon Web Services, т.к. нужно было создать инструментарий, чтобы эти команды были самодостаточными.

В случае географически распределенных команд, отвечающих за один и тот же сервис возникает проблема коммуникации (особенно между разными часовыми поясами) между командами когда необходимо делать изменения в фактически общий сервис. Соответственно есть 2 варианта к чему это может привести - либо коммуникация будет улучшена, либо изменения со временем просто перестануть вноситься, т.к. это проще. Т.о. автор говорит, что в случае распределенных команд, лучше каждой отдать независимые части системы под разработку и это заодно послужить драйвером для декомпозирования системы.

**Поскольку мы стремимся имплементировать сервисы в Bounded Context, то и организациия команд должна строиться внутри Bounded Context**. Это даст преимущества в том, что все сервисы внутри одного Bounded Context скорее всего общаются между собой, их легче поддерживать и деплоить все вместе, кроме того команда внутри одного Bounded Context будет теснее знакома с этой частью бизнисе и ей проще будет выстроить отношения со стейкхолдером.

В общем, Закон Конвея подчеркивает риски, связанные с попыткой навязать дизайн системы, который не соответствует внутренней структуре организации. Это приводит нас к выводу, что лучше всего система работает, когда 

1) за сервисы отвечает команда в одной локации, 
2) которая сама соответствует и выстроена вокруг одного Bounded Context'а организации. 

Когда эти 2 условия не совпадают, мы получаем точки напряжения и потенциальных проблем. Признавая связь между ними, мы обеспечим, чтобы система, которую мы пытаемся создать, имела смысл для организации, для которой мы ее создаем.

### Microservices at Scale

#### Service resilency/failure recovery

**Любая система или оборудование может и обязательно однажды выйдет из строя** - данная мысль заставляет по-другому взглянуть на проблему отказов системы. Вместо того, чтобы сосредотачиваться на построении решения, которое "никогда не выходит из строя", что слишком идеально и невозможно, **лучше сосредоточиться на решении, которое позволит быстро и легко восстановить работоспособность системы, то есть всегда быть готовым к отказам**.

Нужно учитывать, что необходимость в проработке путей восстановления после сбоя зависит от природы самого сервиса. Если он используется пару раз в месяц, то и тратить время на него не стоит. По факту, все время ответа, доступность, отказоустойчивость и т.д. являются кросс-функциональными требованиями, упоминавшимися ранее и должны быть согласованы с бизнесом и пользователями.

Cross-functional requirements can vary from service to service, but I would suggest defining some **general cross-functionals** and then overriding them for particular use cases. When it comes to considering if and **how to scale out your system to better handle load or failure**, start by trying to understand the following requirements:

1. _**Response time/latency**_. How long should various operations take? It can be useful here to measure this with different numbers of users to understand how increasing load will impact the response time. Given the nature of networks, you’ll always have outliers, so setting targets for a given percentile of the responses monitored can be useful. The target should also include the number of concurrent connections/users you will expect your software to handle. So you might say, “We expect the website to have a 90th-percentile response time of 2 seconds when handling 200 concurrent connections per second.”

2.  _**Availability**_. Can you expect a service to be down? Is this considered a 24/7 service? Some people like to look at periods of acceptable downtime when measuring availability, but how useful is this to someone calling your service? I should either be able to rely on your service responding or not. Measuring periods of downtime is really more useful from a historical reporting angle.

3. _**Durability of data**_. How much data loss is acceptable? How long should data be kept for? This is highly likely to change on a case-by-case basis. For example, you might choose to keep user session logs for a year or less to save space, but your financial transaction records might need to be kept for many years.

Once you have these requirements in place, you’ll want a way to systematically measure them on an ongoing basis. You may decide to make use of performance tests, for example, to ensure your system meets acceptable performance targets, but you’ll want to make surecyou are monitoring these stats in production as well!

Если есть требование в случае какого-либо fail'a, чтобы UI и лежащие под ним микросервисы были доступны хотя бы частично, необходимо иметь возможность отключить часть функциональности и иметь заглушки для показа пользователю, а все сервисы относящиеся к UI рассматривать с перспективы "что делать и что показывать поьзователю, если данный сервис или те от кого он зависит выйдут из строя?" и собственно знать ответ на этот вопрос.

