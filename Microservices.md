## Мысли и советы из книги Sam Newman "Building Microservices"

1. **Bounded context** из DDD отлично описывает один микросервис. Если определить все главные **bounded contexts**, то можно каждый выделить в сервис, а каждый сервис может содержать свои внутренние **bounded contexts**.

2. Систему можно начинать проектировать и делать как монолитную в одном солюшне для того чтобы постепенно проявить все внутренние (использующиеся внутри сервиса) и внешние (использующиеся для передачи данных между сервисами) **модели** и **bounded contexts**. Затем, когда все проясниться и устаканиться, можно ее (систему) разбить на микросервисы. **Это совет для новичков**. С опытом систему можно сразу проектировать как микросервисную.

3. При проектировании микросервисов необходимо думать в **контексте возможностей (capabilities)** проектируемого сервиса и того **что он умеет делать**, а не данных которыми он оперирует, иначе выйдет просто CRUD вокруг которого строится сервис. А когда эти возмоности и способности определены - уже можно выделять данные и модели, которые нужны для реализации этих спосбностей.

4. Вариант общения клиента и сервера: гуглить **Richardson Maturity Model и Hypermedia Controls (HATEOAS)**. Фаулер об этом писал, подход прикольный, но походу не получил популярность.

5. Микросервисы должны иметь **low coupling** между друг другом и **high cohesion** внутри себя, что логично. Но **shared** между сервисами база данных или **библиотека с data types** для всех сервисов в итоге неявно увеличивает **coupling**. Кроме того, создание библиотеки клиента для сервиса и использование ее в разных клиентах этого сервиса тоже создает **coupling** между **ВСЕМИ** клиентами и сервисом. Принцип **DRY** тоже можно и нужно нарушать в угоду независимости сервисов друг от друга. Лучше скопипастить какой-то кусок кода с бизнес логикой чем выделять его в библиотеку и шарить ее между сервисами (речь не идет вспомогательных библиотеках типа log4net).

6. Согласно автору **асинхронная event-based** коммуникация между микросервисами через **message broker** типа Rabbit MQ является лучшим вариантом реализации архитектуры микросервисов, так как имеет наименьший **coupling** и микросервисы не знают друг о друге.

7. UI layer за которым стоит множество микросервисов может общаться с ними следующим образом:
	* UI компонент, который шлет запросы всем необходимым сервисам
		- &#9989; SRP - UI сам за себя отвечает и знает что ему нужно
		- &#10060; сообщения могут слаться рассинхронизированно, что жрет много трафика, что критично для мобильной сети
		- &#10060; для получения всей информации надо общаться с несколькими сервисами, т.е. происходит интенсивное использование сети
		- &#10060; скорее всего понадобиться выделенная команда для поддержи UI, а это значит необходима коммуникация между командами, теряется независимость
		- &#10060; увеличиватся **coupling** между сервисами и UI
	
	* Каждый сервис представляет свой UI виджет. Все они собираются в некий box и показываются пользователю.  
		- &#9989; UI каждого сервиса сапортится командой этого сервиса и нет нужды в выделенной UI команде
		- &#9989; **coupling** между UI и сервисами в порядке
		- &#10060; сообщения все равно могут слаться рассинхронизированно, что жрет много трафика, что критично для мобильной сети
		- &#10060; для получения всей информации надо общаться с несколькими сервисами, т.е. происходит интенсивное использование сети
		- &#10060; в случае появления виджета, которому необходимы данные нескольких сервисов снова увеличивается **coupling**		
	* **API Gateway**, что по сути является **фасадом** ко всем сервисам. 
		- &#9989; сервисы и UI независимы друг от друга и развязаны через Gateway
		- &#9989; данные из разныих сервисов могут быть получены UI одном запросом к фасаду, который уже сам знает какие сервисы ему запросить
		- &#10060; при изменении одного сервиса меняется фасад
		- &#10060; фасад может разрастись до огромных размеров и его будет тяжело поддерживать, особенно если учитывать разные виды UI (mobile, web, admin panel) которые могут иметь потребности в разных сервисах, но в итоге объединенный одним фасадом
	
	* Альтернативой, поддерживаемой автором, является **Гибридный подход**, где каждый вид UI (mobile, web, admin panel) имеет свой **API Gateway** (backend-for-frontends)
		- &#9989; сервисы и UI независимы друг от друга и развязаны через Gateway
		- &#9989; разные виды UI независимы друг от друга и от сервисов
		- &#9989; данные из разныих сервисов могут быть получены UI одном запросом к фасаду, который уже сам знает какие сервисы ему запросить
		- &#9989; меньше шансов, что фасад разрастется до огромных размеров
		- &#9989; при изменении одного сервиса меняется только зависимый фасад, если таковой есть
		- &#10060; необходимо поддерживать больше одного фасада
		- &#10060; возможно понадобится выделенная команда, с которой другим надо коммуницировать, что уменьшает независимость
		- &#10060; при изменении сервиса используемого в нескольких фасадах, их придется менять все

8. При необходимости использования какого-либо решения, как архитектор, нужно решить стоит ли это решение писать саммим или взять/купить готовое и внедрить. Опасность готовых решений может быть в том, что оно не полностью подходит и его надо кастомизировать под себя, что бывает не так просто и может дорого стоить и, возможно, проще что-то переделать у себя, чтобы это решение начало работать "из коробки" либо все же написать самим что-то, что не такое громоздкое и гибкое для кастомизации, но подходит идеально под нужды проекта.

9. **Prefer Choreography (event-based communication) over Orchestration (existing of some broker which redirects calls from one microservice to another and knows about all microservices)**

### Политика работы с базами данных в Микросервисной архитектуре

1. Избегать **foreign keys** в базах и соединять данные в коде сервисов, поскольку это соединение является частью бизнес-логики. Таком образом, мы избавляемся от лишнего **coupling** внутри базы данных. Недостатком данного подхода является увеличение количества обращений к базе.

2. Для того, чтобы один сервис не тянул данные из разных таблиц, о которых по логике ему не положено знать, модно сделать API call к другому сервису, которые оперирует данными из другой таблицы. Но в случае этого call'a не тащить **все** данные, а только **нужные**. Проблемой здесь является то, что теперь все **consistency checks** ложатся на плечи сервисов.

3. **Shared Static data** желательно тоже не хранить в общей таблице, а продублировать эти данные для каждого сервиса, или вообще положить их как часть кода каждого сервиса или выделить в отдельный сервис, если существует сложная бизнес-логика связанная с этими данными. Все ради уменьшения **coupling**, даже дублирование данных (х.з., стоит ли оно того).

4. **Shared Dynamic data**, например **Customer data**, которые могут быть нужны нескольким сервисам (Order, Discount, Delivery etc.) возможно стоит выделить в отдельный **Customer service** и обращаться к нему из разных сервисов, а он сам по себе будет уже управлять данными о **Customers**.

5. **Shared tables**, случай похожий на предыдущий, но в выделении отдельного сервиса нет смысла, так как не проглядыватся bounded context или какой-то сложной логики работы с данной таблицей. Тогда, можно саму таблицу разбить на столько частей, сколько сервисов ее использует и записать в каждую из новых таблиц только те данные, которые нужны конкретному сервису.

6. Книга **Refactoring Databases by Scott J Amber** в помощь

7. При рефакторинге монолитной архитектуры в микросервисную надо разбивать базу и выделяит сервисы **поэтапно**, тестируя изменения на каждом этапе.

8. При существовании множества сервисов обращающихся к базе появляется понятие **distributed transaction** и **eventual consistency**. Есть разные способы для работы в такой парадигме
	- **compensating transaction** - если одна из частей транзакции провалилась (вставка в данных разные таблицы разными сервисами в рамках одной бизнес-операции), то запускается механизм отката уже свершившихся частей транзакции. Проблема здесь в том, что **compensating transaction** тоже может провалиться, тогда нужен какой-то **retry** или **clean up/reconciliation**  по расписанию, но менеджить транзакции состоящие из 3-х, 4-х, 5-ти... частей все равно становиться слишком сложно.
	- **two-phase commit**. С этим подходом сначала идет **voting phase**, где каждый учасник транзакции (называемый _cohort_) говорит **transaction manager**, что он готов к обработке транзакции. Каждый учасник должен сказать _yes_, тогда **transaction manager** сообщает всем учасникам, что они могут выполниьт свои часть транзакции, а в случае хотя бы одного _no_ вся транзакция не выполняется. Здесь все равно есть риск, что какой-то участник провалит свою часть транзакции даже после того как он отправил _yes_, поэтому действует предположение, что после _yes_ транзакция выполнится в любом случае. Кроме того, присутствует _bottleneck_ в виде **transaction manager** от которго все зависят. Процесс координирования также означает наличие **lock'ов** на данных пока идет транзакция, что в случае **outage** влияет на всю систему и плохо для масштабирования.
	- в итоге, если часть системы нуждается в **реальной постоянной согласованности**, возможно, ее не стоит биь на части в виде микросервисов и отдельных вызовов к базе. Тогда транзакции можно отдать на откуп базе данных, в чем она хороша. Иначе же, можно обойтись **eventual consistency**.
	
9. В части **REPORTING** (примерно стр. 174) дается несколько советов о том, как можно организовать **reporting** часть системы. Здесь описывать все нет смысла, лучше обратиться к первоисточнику.

