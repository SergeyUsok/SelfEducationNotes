## Good practices for high-performance and scalable applications (Node.js example)

 - https://medium.com/iquii/good-practices-for-high-performance-and-scalable-node-js-applications-part-1-3-bb06b6204197
 - https://medium.com/iquii/good-practices-for-high-performance-and-scalable-node-js-applications-part-2-3-2a68f875ce79
 - https://medium.com/iquii/good-practices-for-high-performance-and-scalable-node-js-applications-part-3-3-c1a3381e1382

### Варианты горизонтального масштабирования приложения:

1. Множество процессов на одной машине (каждый процесс - это экземпляр нашего сервиса). При такой архитектуте необходимо выделить **master**-процесс и **worker**-процессы для каждого ядра. **Master**-процесс используя round-robin механизм распределяет нагрузку и входящие запросы между **worker**-процессами. С точки зрения кода, это все будет один и тот же сервис с неким if-ом, по которому собственно и определяем режим работы данного экземпляра (master или worker).

2. Все тоже самое, что и в первом случае, но используя **third-party process manager** как **master**. Для Node.js, например, это **PM2**.

3. Множество машин с сетевым **load balancing**. Согласно архитектуре, имеем несколько машин, на которых установлены несколько экземпляров нашего сервиса, то есть каждая машина представляет собой пункты 1 или 2. Балансировщик между машинами можно использовать какой-нибудь уже готовый (например, Elastic Load Balancer в AWS). Можно добавить несколько балансеров и распределять трафик между ними через DNS Resolver.

### Как сделать сервис готовым для масштабирования:

1. Необходимо разворачивать экземпляры приложения и базы данных (включая in-memory caches типа Redis) на отдельных машинах, чтобы их можно было масштабировать отдельно друг от друга.

2. Сервисы должны быть **stateless**, так как их несколько экземпляров и к какому конкретно попадет один и тот же пользователь между разными запросами - неизвестно. Конфигурации и настройки, которые могут измениться во время работы приложения, надо хранить во внешнем хранилище (база, файловая система или Redis-like база), чтобы все экземпляры могла подхватить эти изменения.

3. Аутентификация и авторизация требует хранения информации о том, что текущий пользователь залогинен и авторизован на всех экземплярах приложения, но при этом он не должен вводить свои credentials каждый раз, когда балансер переключается между экземплярами приложения. Варианты решения данной проблемы:

- Настроить Load balancer всегда перенаправлять запросы от одного и того же пользователя на один и тот же сервис. Но это довольно сложно менеджить и частичто убивает независимость сервисов и масштабирование.
- Хранить данные сессии в базе или на файле, но множественные I/O операции плохо влияют на производительность.
- Немоного проще и производительнее хранить данные в кэше типа Redis, но требует больше оперативной памяти
- Использовать JWT токены - JSON Web Tokens, хранить их на клиенте в куках и пересылать их при каждом запросе на сервер, а сам сервер уже может их процессить и проверять является ли данный токен настоящим и аутентифицирован ли пользователь. Т.к. JWT не зашифрован и просто хранится в base64, то для их передачи необходимо использовать SSL канал. 

4. Хранить user=-generated assets не в файловой системе, посколько они будут доступны только на одной машине, а в каком-то специализированном сервисе, типа S3 от Amazon и сохранять в базу только URI для этих ресурсов. Все экземпляры приложения смогут получить эти URI из базы и сами ресурсы по URI.

5. Для real-time общения между сервером и клиентом или между клиентами использовать WebSocketsа, а Redis для pub-sub функциональностии и как медиатор между экземплярами пролижения. Long-polling не подойдет поскольку требует постоянной сессии, от чего мы пытаемся уйти.

## Тезисы из книги Sam Newman "Building Microservices"

### Моделирование сервисов и их интеграция и взаимодействие между собой

1. **Bounded context** из DDD отлично описывает один микросервис. Если определить все главные **bounded contexts**, то можно каждый выделить в сервис, а каждый сервис может содержать свои внутренние **bounded contexts**.

2. Систему можно начинать проектировать и делать как монолитную в одном солюшне для того чтобы постепенно проявить все внутренние (использующиеся внутри сервиса) и внешние (использующиеся для передачи данных между сервисами) **модели** и **bounded contexts**. Затем, когда все проясниться и устаканиться, можно ее (систему) разбить на микросервисы. **Это совет для новичков**. С опытом систему можно сразу проектировать как микросервисную.

3. При проектировании микросервисов необходимо думать в **контексте возможностей (capabilities)** проектируемого сервиса и того **что он умеет делать**, а не данных которыми он оперирует, иначе выйдет просто CRUD вокруг которого строится сервис. А когда эти возмоности и способности определены - уже можно выделять данные и модели, которые нужны для реализации этих спосбностей.

4. Вариант общения клиента и сервера: гуглить **Richardson Maturity Model и Hypermedia Controls (HATEOAS)**. Фаулер об этом писал, подход прикольный, но походу не получил популярность.

5. Микросервисы должны иметь **low coupling** между друг другом и **high cohesion** внутри себя, что логично. Но **shared** между сервисами **база данных** или **библиотека с data types** в итоге неявно увеличивает **coupling**. Кроме того, создание библиотеки клиента для сервиса и использование ее в разных клиентах этого сервиса тоже создает **coupling** между **ВСЕМИ** клиентами и сервисом. Принцип **DRY** тоже можно и нужно нарушать в угоду независимости сервисов друг от друга. Лучше скопипастить какой-то кусок кода с бизнес логикой чем выделять его в библиотеку и шарить ее между сервисами (речь не идет вспомогательных библиотеках типа log4net).

6. Некоторые best practicies интеграции микросервисов между собой:
	- Avoid Breaking Changes (existing consumers shouldn’t be impacted), use versioning API
	- Keep Your APIs Technology-Agnostic
	- Make Your Service Simple for Consumers
	- Hide Internal Implementation Detail (do not let service consumers to be bound to service's internal implementation)

7. Согласно автору **асинхронная event-based** коммуникация между микросервисами через **message broker** типа Rabbit MQ является лучшим вариантом реализации архитектуры микросервисов, так как имеет наименьший **coupling** и микросервисы не знают друг о друге.

8. UI layer за которым стоит множество микросервисов может общаться с ними следующим образом:
	* UI компонент, который шлет запросы всем необходимым сервисам
		- &#9989; SRP - UI сам за себя отвечает и знает что ему нужно
		- &#10060; сообщения могут слаться рассинхронизированно, что жрет много трафика, что критично для мобильной сети
		- &#10060; для получения всей информации надо общаться с несколькими сервисами, т.е. происходит интенсивное использование сети
		- &#10060; скорее всего понадобиться выделенная команда для поддержи UI, а это значит необходима коммуникация между командами, теряется независимость
		- &#10060; увеличиватся **coupling** между сервисами и UI
	
	* Каждый сервис представляет свой UI виджет. Все они собираются в некий box и показываются пользователю.  
		- &#9989; UI каждого сервиса сапортится командой этого сервиса и нет нужды в выделенной UI команде
		- &#9989; **coupling** между UI и сервисами в порядке
		- &#10060; сообщения все равно могут слаться рассинхронизированно, что жрет много трафика, что критично для мобильной сети
		- &#10060; для получения всей информации надо общаться с несколькими сервисами, т.е. происходит интенсивное использование сети
		- &#10060; в случае появления виджета, которому необходимы данные нескольких сервисов снова увеличивается **coupling**		
	* **API Gateway**, что по сути является **фасадом** ко всем сервисам. 
		- &#9989; сервисы и UI независимы друг от друга и развязаны через Gateway
		- &#9989; данные из разныих сервисов могут быть получены UI одном запросом к фасаду, который уже сам знает какие сервисы ему запросить
		- &#10060; при изменении одного сервиса меняется фасад
		- &#10060; фасад может разрастись до огромных размеров и его будет тяжело поддерживать, особенно если учитывать разные виды UI (mobile, web, admin panel) которые могут иметь потребности в разных сервисах, но в итоге объединенный одним фасадом
	
	* Альтернативой, поддерживаемой автором, является **Гибридный подход**, где каждый вид UI (mobile, web, admin panel) имеет свой **API Gateway** (backend-for-frontends)
		- &#9989; сервисы и UI независимы друг от друга и развязаны через Gateway
		- &#9989; разные виды UI независимы друг от друга и от сервисов
		- &#9989; данные из разныих сервисов могут быть получены UI одном запросом к фасаду, который уже сам знает какие сервисы ему запросить
		- &#9989; меньше шансов, что фасад разрастется до огромных размеров
		- &#9989; при изменении одного сервиса меняется только зависимый фасад, если таковой есть
		- &#10060; необходимо поддерживать больше одного фасада
		- &#10060; возможно понадобится выделенная команда, с которой другим надо коммуницировать, что уменьшает независимость
		- &#10060; при изменении сервиса используемого в нескольких фасадах, их придется менять все

9. При необходимости использования какого-либо решения, как архитектор, нужно решить стоит ли это решение писать саммим или взять/купить готовое и внедрить. Опасность готовых решений может быть в том, что оно не полностью подходит и его надо кастомизировать под себя, что бывает не так просто и может дорого стоить и, возможно, проще что-то переделать у себя, чтобы это решение начало работать "из коробки" либо все же написать самим что-то, что не такое громоздкое и гибкое для кастомизации, но подходит идеально под нужды проекта.

10. **Prefer Choreography (event-based communication) over Orchestration (existing of some broker which redirects calls from one microservice to another and knows about all microservices)**

### Политика работы с базами данных в Микросервисной архитектуре

1. Избегать **foreign keys** в базах и соединять данные в коде сервисов, поскольку это соединение является частью бизнес-логики. Таком образом, мы избавляемся от лишнего **coupling** внутри базы данных. Недостатком данного подхода является увеличение количества обращений к базе.

2. Для того, чтобы один сервис не тянул данные из разных таблиц, о которых по логике ему не положено знать, модно сделать API call к другому сервису, которые оперирует данными из другой таблицы. Но в случае этого call'a не тащить **все** данные, а только **нужные**. Проблемой здесь является то, что теперь все **consistency checks** ложатся на плечи сервисов.

3. **Shared Static data** желательно тоже не хранить в общей таблице, а продублировать эти данные для каждого сервиса, или вообще положить их как часть кода каждого сервиса или выделить в отдельный сервис, если существует сложная бизнес-логика связанная с этими данными. Все ради уменьшения **coupling**, даже дублирование данных (х.з., стоит ли оно того).

4. **Shared Dynamic data**, например **Customer data**, которые могут быть нужны нескольким сервисам (Order, Discount, Delivery etc.) возможно стоит выделить в отдельный **Customer service** и обращаться к нему из разных сервисов, а он сам по себе будет уже управлять данными о **Customers**.

5. **Shared tables**, случай похожий на предыдущий, но в выделении отдельного сервиса нет смысла, так как не проглядыватся bounded context или какой-то сложной логики работы с данной таблицей. Тогда, можно саму таблицу разбить на столько частей, сколько сервисов ее использует и записать в каждую из новых таблиц только те данные, которые нужны конкретному сервису.

6. Книга **Refactoring Databases by Scott J Amber** в помощь

7. При рефакторинге монолитной архитектуры в микросервисную надо разбивать базу и выделяит сервисы **поэтапно**, тестируя изменения на каждом этапе.

8. При существовании множества сервисов обращающихся к базе появляется понятие **distributed transaction** и **eventual consistency**. Есть разные способы для работы в такой парадигме
	- **compensating transaction** - если одна из частей транзакции провалилась (вставка в данных разные таблицы разными сервисами в рамках одной бизнес-операции), то запускается механизм отката уже свершившихся частей транзакции. Проблема здесь в том, что **compensating transaction** тоже может провалиться, тогда нужен какой-то **retry** или **clean up/reconciliation**  по расписанию, но менеджить транзакции состоящие из 3-х, 4-х, 5-ти... частей все равно становиться слишком сложно.
	- **two-phase commit**. С этим подходом сначала идет **voting phase**, где каждый учасник транзакции (называемый _cohort_) говорит **transaction manager**, что он готов к обработке транзакции. Каждый учасник должен сказать _yes_, тогда **transaction manager** сообщает всем учасникам, что они могут выполниьт свои часть транзакции, а в случае хотя бы одного _no_ вся транзакция не выполняется. Здесь все равно есть риск, что какой-то участник провалит свою часть транзакции даже после того как он отправил _yes_, поэтому действует предположение, что после _yes_ транзакция выполнится в любом случае. Кроме того, присутствует _bottleneck_ в виде **transaction manager** от которго все зависят. Процесс координирования также означает наличие **lock'ов** на данных пока идет транзакция, что в случае **outage** влияет на всю систему и плохо для масштабирования.
	- в итоге, если часть системы нуждается в **реальной постоянной согласованности**, возможно, ее не стоит биь на части в виде микросервисов и отдельных вызовов к базе. Тогда транзакции можно отдать на откуп базе данных, в чем она хороша. Иначе же, можно обойтись **eventual consistency**.
	
9. В части **REPORTING** (примерно стр. 174) дается несколько советов о том, как можно организовать **reporting** часть системы. Здесь описывать все нет смысла, лучше обратиться к первоисточнику.

### Deployment и CI/CD в мире микросервисов

1. Желательно делать билды для каждого микросервиса отдельно и ребилдить только тот микросервис, который был изменен а не всю экосистему сервисов. Исключением является случай, когда разработка новой системы или рефакторинг монолита в микросервисы только начинается и границы сервисов и их API еще не определены, поэтому имеет смысл бандлить все **пока** как один солюшн и один билд.

2. **Build pipeline** - это концепция поэтапной сборки, интергрирования и развертывания приложения. В случае проблем на каком-то из этапов нет необходимости начинать следующий этап. **Build pipeline** дает возможность отслеживать прогресс изменений software и контролировать его качество. Релиз процесс как **build pipeline:**

_Compile and fast tests_ -> _Slow tests_ -> _UAT_ -> _Performance tests_ -> _Production_

3. **Continuous delivery (CD)** построено на концепции **Build pipeline** и является подходом, при котором мы получаем постоянный feedback о готовности к production release для каждого коммита и трактуем каждый коммит как release-кандидат.

4. Варианты хостинга сервисов
	- Multiple services per host
	- Application container with multiple services inside per single host
	- Single service per host
	- PaaS

5. **Автоматизация** - ключ к простоте управления (handling) множеством сервисов. Перед переходом с монолита на микросервисы прежде всего необходимо автоматизировать процессы сборки, развертывания и мониторинга, а после уже рефакторить и переделывать систему.

9. В части **From Physical to Virtual** (примерно стр. 217) говорится о **контейнеризации** и **виртуализации**, упоминаются несколько полезных инструментов, в том числе и Docker.

10. **SUMMARY**
	- Focus on maintaining the ability to release one service independently from another, and make sure that whatever technology you select supports this.
	- Author suggests to have a single repository per microservice and one CI build per microservice for deploying them separately.
	- Have single-service-per-host/container (use Docker or LXC to make managing the moving parts cheaper and easier)
	- Automate everything, if choosen technology does not allow automation, choose another technology, because **automation is a KEY to easy manageability**
	- Going deeper into this topic read the book by Jez Humble and David Farley "Continuous Delivery" 

### Тестирование микросервисов

1. Brian Marick's testing quadrant:

![Brian Marick's testing quadrant](https://lisacrispin.com/wp-content/uploads/2011/11/Agile-Testing-Quadrants.png)

2. Mike Cohn's test pyramid

![Mike Cohn's test pyramid](https://martinfowler.com/articles/practical-test-pyramid/testPyramid.png)

3. **Unit tests** - это **small-scoped** тесты и их главная цель дать **быстрый** _feedback_ о том насколько хорошо написанная функциональность работает.

4. **Service tests** - тестируют возможности и функциональность отдельного сервиса. Можно сказать, это **middle-scoped** тесты, они могут быть быстрыми как unit, так и долго выыполняющимися при, например, интеграции с реальной базой или другими сервисами.

5. **End-to-end tests (UI in Mike Cohn's test pyramid)** - тесты для всей системы в целом. Это **large-scoped** тесты. Когда они успешно выполняются можно быть более-менее уверенным, что система работает (при условии, что тесты написаны корректно).

6. Чем больше **testing scope** тем медленней тесты работают и долшье ждать feedback. Однако чем более изолированней тесты (меньше scope) тем меньше информации о том как система себя поведет в целом.

7. Следуя принципу **Fail fast** в build pipeline необходимо настраивать тестовый прогон в порядке увеличения **testing scope**, т.е. сначала unit, потом service, а потом end-to-end тесты.

8. Есть несколько проблем с **large-scoped** тестами:
	- В случае с интеграционными тестами (service tests) или end-to-end тестами, какие версии других сервисов (от которых зависит наш тестируемый) брать для тестирования? Продакшн версии или последнии из UAT?
	- При наличии в активной разработке нескольких сервисов, как ранить end-to-end тесты и трактовать их результаты, если несколько сервисов были изменены?

Эти проблемы можно решить наличием нескольких веток build pipeline'ов с unit и service тестами, которые при положительном результате каждой ветки объединиются и ранять общие для всех end-to-end tests.

Еще одной проблемой end-to-end тестов в случае, когда есть несколько команд и каждая отвечает за свой сервис, является то, что не очевидно, кто должен реагировать, если они упали. Решением может быть дежурства каждой команды, по-спринтово, например.

9. **Test Journeys, Not Stories**. Это значит, что не надо добавлять на каждую user-story по end-to-end тесту, поскольку они обычно долго ранятся и управлять ими и их зависимостями сложно, то в end-to-end лучше добавлять тесты, которые проверяют **core** логику системы, а user-story лучше проверять в service тестах в изоляции. **Core логика** - это например, flow заказа в онлайн магазине, начиная от UI и заканчивая доставкой и оплатой и все это один end-to-end тест, который должен работать всегда, независимо от изменений в сервисах.

10. **Consumer-driven contract (CDC)** - это концепция тестирования сервиса с точки зрения _потребителя_ этого сервиса. На пирамиде Mike Cohn'a эти тесты находятся рядом с service тестами, так как тестируют конкретный сервис. Преимущество данных тестов перед обычными интеграционными в том, что они тестируют конкретный реальный сценарий. Кроме того, они могут тестировать **разную** функциональность одного и того же сервиса, но с точки зрения **разных** потребителей. Например, у нас есть _Customer_ сервис, отвечающий за клиентов. У данного сервиса 2 потребителя: _Customer helpdesk_ service и _Delivery_ service. Оба сервиса имеют свои ожидания (expectations) о том, как _Customer_ сервис должен работать. Соответственно создаются два набора **CDC** тестов для каждого аспекта работы _Customer_ сервиса. Хорошей практикой является создание этих тестов в коллаборации между командами _Customer_ и _Customer helpdesk_ сервисов и _Customer_ и _Delivery_ сервисов. Преимущество данных тестов в том, что в случае проблем с тестом, сразу видно какой _потребитель_ заимпакчен. Pact: [link to Pact!](https://github.com/pact-foundation/pact.io) - инструмент для **CDC** тестов.

11. Автор советует предпочесть **CDC** и заменить ими end-to-end тесты, исходя из его опыта и опыта его знакомых, это работает, при этом **CDC** требуют меньше времени для работы, так как имеют меньший _scope_, и более информативны в определении проблемных мест.

12. **TESTING AFTER PRODUCTION**. Не всегда testing environment полностью повторяет production, соответственно во время релиза возникает необходимость протестировать сервисы уже после релиза на production environment'е. Несколько вариантов реализации такого тестирования:
	- _smoke test suite_ - небольшой набор тестов, который прогоняется после релиза и направлен на то, чтобы протестировать места где environment различается между UAT и Production.
	- _blue/green deployment_ - с этим подходом мы имеем 2 копии системы развернутых одновременно, но только одна получает реальные requests. Т.о. старая версия пока работает, а с новой версией прогоняются _smoke tests_. Если тесты в порядке, то мы переключаем систему со старой версии на новую.
	- _canary releasing_ - чем-то схож с _blue/green deployment_, но смысл в том, что мы **постепенно** переключаем proudction со старой версии на новую, когда обе развернуты на production. Каждый раз, переключая какую-то часть системы сос старой на новую, мы проверяем, что она справляется с нагрузкой и функционально ведет себя правильно. На каждом этапе, в случае каких-либо проблем, мы имеем возможность откатить систему. С таким подходом можно также копировать запросы, которые идут к старой production системе, в новую и сравнивать как они себя ведут. Netflix использует _canary releasing_.
	
13. Нужно учитывать, что какими бы не были отличными тесты и какое бы покрытие не было бы достигнуто - от всех проблем не удастся избавиться и они однажды проявятся на проде. Здесь в игру вступает **Mean Time to Repair (MRTR) vs Mean Time Between Failures (MTBF)**. Необходимо искать компромисс между этими характеристиками системы и иметь большой MTBF (что обеспечивается хорошими тестами), но и иметь адекватный MRTR и быть готовым ко сбоям в системе, то есть иметь некую стратегию на случай отказа системы.

14. Большой объем тестов кроется под термином **nonfunctional tests**, которые автор предпочитает называть **cross-functional tests**, поскольку они охватывают различные аспекты системы (performance, UI validity in terms of HTML, HTML accessability for disabled people, scalability, etc.) Такие тесты обычно возможно провести только на проде в реальных условиях, но во время разработки и тестирования, по крайней мере, можно разработать стретегии тестирования и трекать, движемся ли мы в правильном направлении. С учетом широкого охвата различных аспектов системы данными тестами, их можно и нужно приоритезировать и учитывать, так как часто надежность и доступность одного аспекта системы важнее другого, например надежность платежного сервиса явно важнее чем произодительность рекомендательного. Автор советует учитывать данные тесты с ранних стадий разработки, а не откладывать их на потом.

15. **Performance Tests**. Пожалуй, в мире микросервисов, Performance Tests еще важнее чем в Монолите, поскольку теперь появляются множество акторов, которые взаимодействуют между собой по сети, каждый из них может обращаться к базам данных, что увеличвает в целом количество IO операций по сравнению с Монолитом. Данные тесты практически бесполезны в изоляции, поэтому часто из откладывают на потом, но автор советует покрывать ими Core части системы и основные Journes, даже когда вся система еще не написана. Понятно, что данный тип тестов требует prod-like окружения и объемов данных, сами тесты могут выполняться долго, поэтому хорошей практикой является прогон некоторого подмоножества тестов каждый день и основного множества раз в неделю. **Важным также является определить цели (targets) этих тестов, то есть числа производительности, по которым можно понять, что тест прошел или упал.** Иначе есть шанс, что на результаты никто не будет обращать внимания.

### Monitoring

**Monitor the small things, and use aggregation tosee the bigger picture**.

Logging is a key to proper monitoring. Some tools mentioned by author:
- **Kibana** is an ElasticSearch-backed system for viewing logs
- **Graphite** is an system for storing, querying and viewing metrics. It allows view aggregated metrics for the whole system (e.g. CPU load), aggregated metrics for all instances if concrete service or just concrete instance of concrete service.

Автор рекомендует, чтобы сервисы свои базовые выставляли наружу сами по себе. Это облегчит мониторинг для внешних инструментов и даст понимание какие фичи данныъ сервисов используются чаще, чем другие. Например, Customer service может выдавать метрику о том, сколько покупателей и как часто смотрят на свои предыдущие заказы. Это полезно знать, например, для того нужно ли дальше поддерживать фичу или стоит ее как-то улучшить или оптимизировать.

**Synthetic transaction** - транзация, которая запускает в цепь событий и калькуляций в системе имитирующих реальные события и калькуляции. **Semantic monitoring** - техника, с использованием **Synthetic transaction**, собиранием метрик на основе данной транзации и последующая оценка данных метрик.

В микросервисной архитектуре множество сервисов общаются между собой, что приводит к сложной цепочки вызовов. Если на каком-то этапе произойдет ошибка, будет трудно отследить в логах какой именно вызов привел к ней, так как сервисы обрабатываебт множество вызовов одновременно. Для целей отслеживания всей цепи вызовов инициированной конкретным вызовом автор рекмендует использовать **Correlation ID** - механизм, с помощью которого можно отслеживать цепочку вызовов-ответов между различными сервисами. Инициирующий некую служную (требующую участия множества сервисов) операцию сервис генерирует уникальный **Correlation ID** и пробрасывает его дальше в вызовах, последующие сервисы, видя наличие ID, тоже пробрасываеют его дальше и логируют. Т.о. можно отследить в логах конкретный реквест.

Track the health of all downstream responses, at a bare minimum including theresponse time of downstream calls, and at best tracking error rates. Libraries likeHystrix can help here.

Автор советует иметь некую стандартизацию в логах сервисов, для того чтобы было проще аггрегировать информацию. Например, один сервис может писать ResponseTime в логах, а другой RspTimeSecs, хотя эти данные значат одно и тоже. Вот для этого и нужно стандартизировать внутри команд такие core вещи.

Книга этого же автора про мониторинг: [https://www.oreilly.com/webops-perf/free/lightweight-systems.csp]

### Security

Монолит сам обрабатыват и содержит логику аутентификации и авторизации. В случае микросервисов такой подход не работает, поскольку мы не хотим чтобы пользователь логинился в каждый микросервис учавствующий в обработке его запроса. **Необходим SSO (Single Sign On)**

SAML (security assertion markup language) - старая реализация SSO.
OpenID Connect - замена SAML, новая реализация SSO

Одна из реализации данного подхода - это **SSO Gateway**. Пользователь делает вызов, который идет в **SSO Gateway**, тот в свою очередь перенаправляет его в **Identity Provider**, который аутентифицирует и аворизует данного пользователя и возвращает эти данные в **SSO Gateway**. Затем **SSO Gateway** вызывает уже непосредственно необходимый сервис с Principal info and Roles в HTTP заголовке. Т.о. все запросы к сервисам уже преаторизированы. Проблема данного подхода в том, что мы имеем **single point of failure**,  к тому в области безопасности. 

Автор рекомендует придерживаться принципа **defense in depth** — from network perimeter, to subnet, to firewall, to machine, to operating system, to the underlying hardware. Тогда аутентификацию можно доверить **SSO Gateway**, а без **defense in depth** получается, что "все яйца хранятся в одной корзине".

**_Роли авторизации рекумендуется создавать так, чтобы они повторяли структуру предприятия_**

#### Общение сервисов внутри сетевого периметра

Общение сервисов внутри сетевого периметра (т.е. внутри предприятия без участия интернета) можно не использовать аутентификацию. Но здесь есть опасность атаки man-in-the-middle, если кто-то пробьет сетевой барьер и вмешиается в запрос между сервисами. Поэтому совсем без security нельзя обойтись. Несколько вариантов защищенного общения между сервисами:

- использовать **Basic HTTP Auth** для общения между сервисами внутри периметра и шифровать трафик с помощью HTTPS внутри сети, т.к. парольи юзернейм не безопасно слать по обычному HTTP. Но здесь возникают трудности с выпуском и дальнейшим управением SSL сертификатами для работы по HTTPS. 
- использовать уже **существующую (если это так) инфраструктуру SAML или OpenID Connect**.
- можно использовать **клиентские сертификаты**, тогда это будет точно гарантировать, что клиент действитеьно тот, за кого себя выдает, но здесь проблема опять же с выпуском и дальнейшим управением SSL сертификатами, причем еще хуже чем в первом случае.
- **hash-based messaging code (HMAC)** - механизм работает так: генерится хеш на основе информции в запросе с помощью приватного ключа и хеш посылается вместе с запросом. На стороне сервера (который тоже хранит этот приватный ключ) опять генерим хеш и если он совпадет с пришедшим, значит информация верна. Проблема с этим подходом в том, что нужно как-то синхронизировать приватные ключи у клиента и сервера, если их переодически передавать, то снова необходим ОЧЕНЬ ЗАЩИЩЕННЫЙ механизм, если их хардкодить, то в случае компроментации их труднее будет заменить. Еще одна проблема в том, что сама информация в запросе доступна сниферам, они просто не смогут пометить в нее что-то свое.
- **API keys** - данный подход испоьзуют такие компании как Twitter, Google, Flickr, AWS для работы с их public API. С помощию данного механизма можно управлять не только доступом к ресурсу, но и ограничивать частоту использования и т.п. Вариантов реализации тоже множество, некоторые системы используют единый ключ и тогда подход стновится схожим с HMAC, некоторые используют пару публичный-приватный ключ, некоторые позволяют проложит мост между API ключем и Directory Service организации и таким образом сразу управлять доступом по роляим опираясь на информацию из Directory Service.

**The Deputy Problem** - проблема, при которой авторизованный пользователь может запросить данные, которые относятся к другому пользователю, используя сервис-посредник. Например, пользователь может узнать статус своего заказа в оналайн-магазине, для этого shopping service (сервис-посредник, который провел аутентификацию) обращается к order service (который без всякой аутентификации доверяет сервису-посреднику) и тот возвращает данные. Поскольку пользоваель авторизован, а для общения между сервисами **внутри периметра** может использоваться что угодно из перечисенных выше вариантов (API keys, HMAC, etc.) то нет никаких ограничений на то, чтобы отдать данному пользователю данные о чужом заказе. Данная проблема не имеет конкреного решения, поскольку она комплексная. Есть некоторые варианты из которых можно исходить в зависимости от чувствительности информации, которую так модно получить - неявное доверие, т.е. просто забить, проверка пользователя, который вызвал сервис и отклонение запроса в случае провала проверки или вообще редирект на ввод учетных данных запрашиваемого пользователя. _Необходимо знать что такая проблема существует_.

#### Защита хранимых данных

- Автор рекомендует шифровать хранимые данные, причем не писать свои велосипеды/алгоритмы шифрования, а использовать хорошо зарекомендовавшие себя решения.
- Пароли хешировать с солью
- Ключи для шифрования НЕ ХРАНИТЬ в той же базе, которую они шифруют, а использовать отдельное хранилище ключей или использовать встроенные возможности движка базы данных, если такие имеются
- Поскольку шифровка и дешифровка требуют вычислительных мощностей, необходимо решить какие данные действительно необходимо шифровать, а какие нет. Например, логи можно не шифровать, но тогда необходимо учитывать какую информацию туда писать.
- Автор рекомендует шифровать все данные как тоько они появятся и всегда иметь их зашифрованными, а дешифровать по требованию.
- Бекапы ТОЖЕ неоходимо ШИФРОВАТЬ, а не оставлять их так.

#### Defence in Depth

- Firewalls - genral and specific ones 
- Логирование - не защита, но хорошо агрегированные логи могут показать, что где-то что-то идет не так
- **Intrusion detection systems (IDS)** can monitor networks or hosts for suspicious behavior, reporting problems when it sees them. **Intrusion prevention systems (IPS)**, as well as monitoring for suspicious activity, can step in to stop it from happening.
- Network segregation
- DO NOT FORGET AND IGNORE patches for servers' OS.

**_Решение о методах защиты данных (насколько строго нужно обезопасить данные) должно приниматься исходя из природы и ценности информации, которую эти данные несут_**

**_Необходимо также думать о механизме отзыва прав доступа у бывших сотрудников, т.к. нет более знакомого с вашей системой человека чем озлобленный бывший сотрудник, который может причинить больше вреда чем внейшний злоумышленник_**

**_Золотым правилом является не изобретать колесо, т.е. не придумывать свои алгоритмы шифрования и протоколы безопасности_**

Некоторые термины и ссылки:
- OWASP - https://habr.com/ru/company/simplepay/blog/258499/
- Microsoft Security Development Lifecycle (SDL) - https://www.microsoft.com/en-us/securityengineering/sdl

### Conway's law (Закон Конвея)

**Любая организация, которая проектирует систему (в т.ч. информационную), неизбежно создаст проект, структура которого является копией коммуникационной структуры организации.** Это же можно выразить так, что если в вашей организации есть четыре команды по разработке некоего компилятора, то в итоге вы получите 4-х этапный компилятор.

В "Exploring the Duality Between Product and Organizational Architectures" (Harvard Business School) авторы Alan MacCormack, John Rusnak, и Carliss Baldwin рассматривают ряд различных программных систем, которые в общих чертах классифицируются как созданные либо _слабо связанными_, либо _тесно связанными_ организациями. 

_Тесно связанные_ организации (фирмы, выпускающие коммерческие продукты), как правило, имеют четкие цели и видение своего продукта, в то время как _слабосвязанные организации_ представлены распределенными сообществами работающими с открытым исходным кодом. 

В своем исследовании, в котором они сравнивали аналогичные пары продуктов из каждого типа организации, авторы обнаружили что более _слабосвязанные организации_ фактически создали более модульные, менее связанные системы, тогда как программное обеспечение _более узко сфокусированной (тесно связанной)_ организации было менее модульным.

**Amazon** осозна преимущества небольших команд, который автономны и полностью отвечают за жизненный цикл системы, которую они разрабатывают. Это привело к правилу 2-pizza teams, то есть команды такого размера, чтобы их модно было накормить 2-мя пиццами. Собственно, такая организция небольших команд ответственных за полный жизненный цикл систем и привела к созданию Amazon Web Services, т.к. нужно было создать инструментарий, чтобы эти команды были самодостаточными.

В случае географически распределенных команд, отвечающих за один и тот же сервис возникает проблема коммуникации (особенно между разными часовыми поясами) между командами когда необходимо делать изменения в фактически общий сервис. Соответственно есть 2 варианта к чему это может привести - либо коммуникация будет улучшена, либо изменения со временем просто перестануть вноситься, т.к. это проще. Т.о. автор говорит, что в случае распределенных команд, лучше каждой отдать независимые части системы под разработку и это заодно послужить драйвером для декомпозирования системы.

**Поскольку мы стремимся имплементировать сервисы в Bounded Context, то и организациия команд должна строиться внутри Bounded Context**. Это даст преимущества в том, что все сервисы внутри одного Bounded Context скорее всего общаются между собой, их легче поддерживать и деплоить все вместе, кроме того команда внутри одного Bounded Context будет теснее знакома с этой частью бизнисе и ей проще будет выстроить отношения со стейкхолдером.

В общем, Закон Конвея подчеркивает риски, связанные с попыткой навязать дизайн системы, который не соответствует внутренней структуре организации. Это приводит нас к выводу, что лучше всего система работает, когда 

1) за сервисы отвечает команда в одной локации, 
2) которая сама соответствует и выстроена вокруг одного Bounded Context'а организации. 

Когда эти 2 условия не совпадают, мы получаем точки напряжения и потенциальных проблем. Признавая связь между ними, мы обеспечим, чтобы система, которую мы пытаемся создать, имела смысл для организации, для которой мы ее создаем.

### Microservices at Scale

#### Service resiliency/failure recovery

**Любая система или оборудование может и обязательно однажды выйдет из строя** - данная мысль заставляет по-другому взглянуть на проблему отказов системы. Вместо того, чтобы сосредотачиваться на построении решения, которое "никогда не выходит из строя", что слишком идеально и невозможно, **лучше сосредоточиться на решении, которое позволит быстро и легко восстановить работоспособность системы, то есть всегда быть готовым к отказам**.

Нужно учитывать, что необходимость в проработке путей восстановления после сбоя зависит от природы самого сервиса. Если он используется пару раз в месяц, то и тратить время на него не стоит. По факту, все время ответа, доступность, отказоустойчивость и т.д. являются кросс-функциональными требованиями, упоминавшимися ранее и должны быть согласованы с бизнесом и пользователями.

Cross-functional requirements can vary from service to service, but I would suggest defining some **general cross-functionals** and then overriding them for particular use cases. When it comes to considering if and **how to scale out your system to better handle load or failure**, start by trying to understand the following requirements:

1. _**Response time/latency**_. How long should various operations take? It can be useful here to measure this with different numbers of users to understand how increasing load will impact the response time. Given the nature of networks, you’ll always have outliers, so setting targets for a given percentile of the responses monitored can be useful. The target should also include the number of concurrent connections/users you will expect your software to handle. So you might say, “We expect the website to have a 90th-percentile response time of 2 seconds when handling 200 concurrent connections per second.”

2.  _**Availability**_. Can you expect a service to be down? Is this considered a 24/7 service? Some people like to look at periods of acceptable downtime when measuring availability, but how useful is this to someone calling your service? I should either be able to rely on your service responding or not. Measuring periods of downtime is really more useful from a historical reporting angle.

3. _**Durability of data**_. How much data loss is acceptable? How long should data be kept for? This is highly likely to change on a case-by-case basis. For example, you might choose to keep user session logs for a year or less to save space, but your financial transaction records might need to be kept for many years.

Once you have these requirements in place, you’ll want a way to systematically measure them on an ongoing basis. You may decide to make use of performance tests, for example, to ensure your system meets acceptable performance targets, but you’ll want to make surecyou are monitoring these stats in production as well!

Если есть требование в случае какого-либо fail'a, чтобы UI и лежащие под ним микросервисы были доступны хотя бы частично, необходимо иметь возможность отключить часть функциональности и иметь заглушки для показа пользователю, а все сервисы относящиеся к UI рассматривать с перспективы "что делать и что показывать поьзователю, если данный сервис или те от кого он зависит выйдут из строя?" и собственно знать ответ на этот вопрос.

**Architectural Safety Measures** - несколько паттернов, которые автор объединил под эти термином. Данные паттерны призваны гарантировать что в случае отказа части системы (одного или нескольких сервисов из множества), вся система будет продолжать работать. Автор рекомендует стандартизировать данные паттерны и строго следовать им в разработке.

1. _**Timeouts**_. Благодаря timeouts клиент может понять, что вызываемый сервис не работает и должным образом обработать данную ситуацию. Здесь главное соблюсти баланс между слишком большим ожиданием, которое может привести к деградации всей системы и слишком коротким, которое по факту приведет к лодному решению о том, что сервис не работает.

2.  _**Circuit Breakers (Предохранители/Выключатели)**_. Данный механизм полезен в связке с timeouts. Поскольку сами по себе timeouts являются просто индикаторами здоровья сервиса, но не предполагают какого-либо реагирования на критические ситуации, выключатель становится тем самым реагировнием. В случае достижения некоего порога по значению или количеству timeouts, Circuit Breaker отключает клиент от неработающего сервиса. Далее возможны разные варианты в зависимости от системы: fail fast, асинхронная очередь запросов в ожидании когда сервис заработает снова, переодическая проверка здоровья сервиса и егообратное включение, если некий порог, показывающий что сервис ок, достигнут.

3. _**Bulkheads (Перегородки)**_. Идея взята из морской терминологии, где перегородки (переборки) позволяют спасти судно в случае течи в одном из отсеков изолировав поврежденный его. Вариантов реализации данного механизма может быть множество, все зависит от системы. Например, можно держать разные connection pools для разных сервисови в случае поблем с одним из сервисов, второй будет работать, т.к. имеет свой connection pool. Есть варианты, когда сам сервис отклоняет запросы, если знает, что он не в порядке. Для всех описанных механизмов есть реализации в виде библиотек, типа [Hystrix
](https://github.com/Netflix/Hystrix) от Netflix для JVM или [Polly](https://github.com/App-vNext/Polly) для .NET.

The Antifragile Organization - концепция проверки устойчивости и гибкости системы путем намеренного создания ситуации отказа какой-либо части системы (вплоть до испольщования специального софта омающего системы в случайное время в случайном месте) и проверки и наблюдаения за тем как система справится с такой ситуацией и все это на проде.

Некоторые тезисы:
- **Idempotency** - свойство объекта или операции при повторном применении операции к объекту давать тот же результат, что довольно полезно реализовать в системах с асинхронным обменом сообщениями через события. Т.о., в случае, если сразу несколько экземпляров одного и того же сервиса получат одно и то же сообщение, с **Идемпотентностью** есть гарантия, что с этим не будет проблем и система останется стабильной.
- HTTP методы **GET** и **PUT** по спецификации являются **идемпотентными**
- **Изоляция наше все**.

#### Масштабирование сервисов

Самое простое - это **вертикальное** мастабирование, т.е. просто увеличение мощности железа. Это относитеьно дешево и быстро, но в итоге дововльно быстро можно достигнуть потолка возможностей железа, кроме того все равно один мощный сервак может быть дороже нескольких попроще, а ПО в силу каких-то своих особенностей может просто не использовать всю его мощь.

**Горизонтальное** масштабирование предпочтительнее. Автор рекомендует иметь один сервис на хост, хотя на начальных этапах вполне вероятна ситуация когда на одном хосте находится множество сервисов, но поскольку каждый сервис это независимый процесс, а общаются они между собой по сети, но в итге разнести их по отдельным хостам не долдно состовлять проблемы. Кроме того, наличие множества хостов увеличивает **resiliency** всей системы.

Надо учитывать, что под понятием хост может скрываться как физическая машина, так и виртуальная, соответственно нужно иметь это тоже в виду при проектировании системы, так как отказ физической машины, на которой множество виртуальных хостов в итоге приведет к отказу множество сервисов, несмотря на то, что вроде как используется модель **service-per-host**. Автор идет дальше и предлагает прогарантировать, что даже если сервисы хостятся на разных машинах, это машины не долдны быть на одной стойке в дата-центре.

Когда сервис должен быть **resilient** самый простой путь добиться этого - это захостить несколько экземпляров сервиса скрытых за **load balancer**'ом. Клиенты этого сервиса будут работать с load balancer'ом и не знать работают они с одним экземпляром или с сотней. Помимо управления запросами ко множеству экземпляров сервиса **load balancer** часто имеет и другие полезные особенности. Одна из часто используемых это **SSL termination** - когда входящие HTTPS запросы к load balancer'у трансформируются в обычные HTTP запросы к экземпляру сервиса. Это сделано из-за сложности управления SSL и соответственно упрощения настройки серверов, хостящих сами сервисы. Однако такой подход подвержен атаке типа _man-in-the-middle_. Чтобы снизить риск такой атаки все экземпляры сервиса помещают в **VLAN (virtual local area network)**, которая изолирована таким образом, что все внешние запросы могут приходить только через определенный роутер, которым и выступает **SSL-terminating load balancer**. То есть единственная коммуникация с внешним миром идет через HTTPS, а внутри все по HTTP. 

![Using HTTPS termination at the load balancer with a VLAN for improved security](https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/bdms_1105-a9976de3951a0fda9f6d72c1010b250e.png)

**Worker-Based Systems** - другой подход нескольких экземпляров сервиса разделять между собой нагрузку. Каждый экземпляр является **worker**'ом и все они берут задачи из какой-то общей очереди (бэклога). Такая архитектура не подходит под все виды работ, но отлично подходит под набор асинхронных задач или batch work. Плюсом также является то, что можно выделять новых worker'ов в пиковые нагрузки и тушить их когда они не нужны. Такая система имеет хороший **resiliency**, т.к. в случае отказа одного worker'а или нескольких, остальные справятся с нагрузкой и система устоит пусть и будет работать медленней, главное чтобы поставщик задач (очередь) был надежен.

**Design for ~10× growth, but plan to rewrite before ~100×**. Писать систему сразу расчитанную на ОЧЕНЬ высокие нагрузки не иммет смысла, т.к. эти нагрузки заранее не известны, а premature optimization плохой подход. Не известно будет ли продукт, для которого пишется система, востребован. Поэтому нужно быть готовым к переписыванию системы в тот момент, когда понятно, что нагрузка постоянно растет и уже близок порог, когда система с ней не справиться. **The need to change our systems to deal with scale isn’t a sign of failure. It is a sign of success**. 

#### Масштабирование баз данных

**Availability of Service Versus Durability of Data** - необходимо разделять эти два понятия, так как система с реплицированной базой, главный интанс которой упал, а механизма переключения сервисов на реплику нет, поддерживает _Durability_, но не поддержиает _Availability_.

**Scaling for Reads**. Обычно в любой системе read операции больше и они происходят чаще, чем write операции. Базируясь на этом можно построить следующую архитектуру базы:

![Using read replicas to scale reads](https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/bdms_1106-a2ed95cf33bb0e34b123a62b33a86d71.png)

Здесь запись в базу происходит в **primary node**, а чтение из реплик, которые периодически синхронизируются с **primary node**. 
Такой подход поддерживает как _Durability_ (реплики), так и _Availability_ (сервисы могут переключаться между репликами). Здесь есть риск чтения устаревших данных, но в конце концов сервис получит последние данные. Это назывется **_eventual consistency_**. Автор утверждает, что использование реплик для чтения раньше было главным способом масштабирования БД, сейчас кэширование позволяет добиться лучших результатов в производительности с меньшими усилиями.

**Scaling for Writes**. Для масштабирования запись в БД используется механизм **sharding**. При этом подходе существует несколько нод базы данных. Во время записи к ключу записываемой строки применяется хэш-функция, основываясь на которой выбирается нужный **shard** (нод). Фактически **sharding** работает по принципу хэш-таблицы. Сложность с таким подходом в том, как запрашивать данные, находящиеся в разных нодах. Можно опрашивать каждый шард и соединять данные вручную в самом приложении, можно иметь отдельный read storage, где все данные сразу доступны. Часто чтение из нескольких шард обрабатывается асинхронно используя кешированные результаты, Mongo для этих целей использует map/reduce jobs. Еще одна проблема в добавлении нового шарада, т.к. после этого необходимо ребалансировать (пересчитывать хэши и перераспределять по шарадам) данные. Некоторые базы могут делать ребалансировку в фоне, например Cassandra. Опять же чистый **sharding** не улучшает **resiliency**, репликация все равно нужна, так как без нее при выходе одной ноды из строя боьшой кусок данных будет недоступен. Разные базы имеют разные возмодности и механизмы шардинга, репликации и т.д. Здесь же нужно конкретно рассматривать каждую из них и выбирать в зависимости как от поставленой задачи, так и от возможностей самой базы.

**CQRS** (Command-Query Responsibility Segregation). _Commands_ изменяют данные, а _Query_ из читают. Использование данного паттерна позволяет разделить запись и чтение настолько, что можно даже использовать разные типы хранилищ данных для разных целей, вплоть до того, что данные для чтения и данные для записи могут храниться в разных форматах. Кроме того, он позволяет использовать т.н. Event Sourcing, т.е. хранить команды в виде списка events. Можно обращаться к этим events, чтобы получить проекцию состояния данных на конкретнй момент, можно, основываясь на них, обновить данные в дургом хранилище и т.д. Т.о. получаем те же преимущества, что и при использовании _реплик для чтения_, но без необходимости хранить данные в том же виде и в том же типе хранилища, которые используются для записи. Недостатком **CQRS** (как и преимуществом одновременно) является то, что скорее всего при реализации этого паттерна исчезает единое хранилище для всех CRUD операций и надо теперь их обрабатывать отдельно с разными хранилищами.

#### Caching

Cache отличный способ оптимизации и улучшения производительности. Кэш можно использовать на стороне клиента, сервера или поставить **reverse proxy** и кэшировать данные там, либо совмещать все подходы вместе. Кэш на сторне клиента уменьшит число запросов по сети, можно закешировать статические данные (CSS, изображения), но если существует несколько типов клиентов (Web, Mobile) и механизм кэширования изменился, то всех клиентов нужно обновлять, что может быть сложно, к тому же инвалидация кэша ложится тоже на плечи клиента. С кэшированием на сервере, так как сервер (сервис) один для всех клиентов и изменять его логику в случае необходимости проще. Кэширование на сервере не уменьшает число запросов по сети, но может например уменьшить число обащений к базе или рекалькуляций каких-то данных. **Reverse proxy** кэширование в общем-то имеет те же преимущества, что и серверное, но с числом дополнительных скачков по сети между прокси и сервисом, что в общем-то не сильно критично.

**Caching in HTTP**. HTTP протокол сам по себе отлично поддерживает кэширование.
	- _cache-control_ - директива, которая может быть отправлена клиенту с указанием того, что кэшировать и насколько долго. _Expires_ заголовок позволяет указать дату и время, когда кэшированные данные устаревают и их нужно запрашивать снова.
	- _Entity Tags or ETags_ - заголовок, который содержит информацию о запрашиваемом клиентом ресурсе и том изменился ли он.
	- _conditional GET_ - при запросе ресурса можно добавить заголвки (_If-None-Match_), говорящие серверу вернуть 200 OK и сам ресурс если он изменился или 304 Not Modified если ресурс не менялся.
	
Автор также рассматривать **Caching for Writes** как более редкий, но вполне используемый варинт кэширования. Например, кэшировать записи в базу в некий буфер, прежде чем их балком записать непосредственно в базу. Это может быть полезно для избежания частый обращейний к базе или если есть шанс, что одни и те же данные могут быть записаны несколько раз и это необходимо исключить.

Еще один вариант использования кэша - **resiliency**. В случае отказа части системы, можно вернуть закэшированную версию тех данных, которую отказавший сервис возвращал.

**Hiding the Origin**. Сервисы, возвращаемые результаты которых кэшируются сервисом-клиентом, обычно мастшабируются так, что обслуживают лишь часть трафика. То есть, раз их результаты кэшируются, значит они высоконагружены и скорее всего горизонтально масштабированы. В случае, если в эеше нет нудных данных, сервис-клиент пойдит в сам сервис-источник этих данных. Когда такое происходит раз или два то ничего страшного, но что если весь кэш надо инвалидировать? Высоконагруженный сервис-источник может просто не выдержать и упасть. Для того чтобы этого не случилось автор предлагет схему, по которой кэш инвалидируется асинхронно в фоне в ответ на событие-триггер промаха мимо кэша, при этом клиенту, которые запросил данные отсутствующие в кэше возвращается ошибка (fail fast), чтобы он не висел и не ждал ответа. То есть в итоге получается, что мы как бы прячем осточник от клиента (Hiding the Origin), и раз нет кэша, то нет и источника. Пример на схеме:

![Hiding the origin from the client and populating the cache asynchronously](https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/bdms_1107-6749ead77f3f24517b808ae3850a5dc6.png)

#### CAP Theorem

Свойства распределенной системы, которые не могут присутствовать в ней одновременно, и могут быть только любые 2 из 3-х.

	- Consistency - согласованность данных, все узлы системы видят одни те же данные в любой момент времени
	- Availability - доступность, гарантирует, что на каждый запрос придет ответ
	- Partition tolerance - устойчивость к разделению, несмотря на разделение на изолированные секции или потери связи с частью узлов, система не теряет стабильность и способность корректно отвечать на запросы

1. AP - наиболее простой способ реализации распределенных систем. В случае потери связи между нодами хранилища данных (да и вообще репликация сама по себе не одномоментна) система по прежнему доступна и распрделена, и _в конце концов будет согласована_, когда связь восстановиться. То есть в такой системе присутствует **eventual consistency**.

2. CP - тяжело иметь согласованность в распределенной системе. Каждый нод должен быть полностью идентичен другому, на время рапликации и даже во время чтения необходимо блокировать затронутые записи данных, что нетривиально в распределенной системе. В случе отказа одного из нодов или потере связи между ними, система полностью отказывет в доступе (как на чтение, так и на запись), так как иначе не может гарантировать согласованность.

3. CA - бессмысленно, т.к. в этом случае система не является распределенной, т.к. в отсутствие Partition tolerance мы не можем работать по сети, все происходить in-process. Как только появляется работа по сети, даже с условной БД без нод и репликаций - появляется и Partition tolerance и распределенность.

_Note: части системы вполне модно реализовывать как AP, а части как CP. Все зависит от предметной области, зоны ответственности конкретного сервиса и архитектора._

#### Service Discovery

Варианты регистрации сервиса в системе и способы нахождения этого сервиса другими:

1. **DNS**. Сервисы могут иметь уникальные URL, можно иметь уникальный URL c префиксом Environment'а (dev, uat, prod), а более продвинутый вариант - иметь отдельный DNS-сервер для каждого Environment'а. Если экземпляров одного сервиса несколько, то иметь URL на Load Balancer для этих экземпляров. Это заодно упрощает включение/выключение экземпляров незаметно для потребителей, ну и решает проблему _DNS time to live (TTL)_, т.к. DNS кэшируется во многих местах и  не всегда очевидно и даже возможно для разработчика обновить запись вручную, а поменять хост под URL необходимость вполне может возникнуть. Некоторые используют round-robin механизм самого DNS для переключения между несколькими хостами когда группа этих хостов соответствует одной записи в таблице DNS, но такой подход чреват проблемами, так как DNS сам по себе не сможет справиться с ситуацией когда один их хостов отказал, чтобы перестать направлять трафик на него.

2. Недостатки DNS как механизма для поиска service endpoints в высокодинамичной среде привели к созданию альтернативных систем, в которых **сервис сам себя регистрирует в некоем центральном реестре, который в свою очередь позволяет клиентам искать зарегистрированные сервисы**. Несколько готовых решений работающих в подобном ключе: Zookeeper, Consul, Eureka (разработка Netflix). Стоит учесть, что все перечисленные инструменты умеют гораздо больше и на самом деле они довльно объемны, а Service Discovery просто одна из их фич.

#### Documenting Services

- Swagger - позволяет создать человеко-читаемую документацию об API сервисов, с хорошим UI и даже возможностью позапрашивать эти сервисы. У него на самом деле больше возможностей и по факту Swagger - это семейство приложений.
- HAL (Hypertext Application Language) - тоже, что и Swagger, но работает с hypermedia controls. Смотреть Richardson Maturity Model, т.е. сервисы должны иметь API как hypermedia controls, иначе HAL бесполезен и лучше для целей документирования использовать Swagger.

### SUMMARY

Принципы микросервисов:

![Principles of microservices](https://miro.medium.com/max/675/1*-qeyTghcJwiBzYmslYFY0Q.png)

- **Model Around Business Concepts** - практика показывает, что интерфейсы смоделлированные вокруг доменной модели, а не технического аспекта более стабильны и позволяют проще реагировать на изменения в собственно бизнес процессах. Необходимо использовать _bounded contexts_ для определения границ сервисов.

- **Adopt a Culture of Automation** - поскольку система построенная на микросервисах иммет большую сложность, необходма максимальная автоматизация всех процессов (от тестирования до развертывания) для того, чтобы справиться с ней.

- **Hide Internal Implementation Details** - делать максимально независимые сервисы, использовать независищее от конкретных технологий способ коммуникации между сервисами (REST здесь в помощь), не связывать сервисы друг с другом неявно, давая использовать им одну БД и т.д.

- **Decentralize All the Things** - автономность команд в реализации, тестировании и развертывании сервисов, которыми они владеют. При необходимости разделения некоего code-base использовать _внутренний open source_ между автономными командами с возможностью pull-request'ов для не-хозяев репозитория. Построение команды в организацию по _закону Конвея_ и возможность стать камандам экспертами в той области бизнеса, за которую они отвечают. Avoid approaches like enterprise service busor orchestration systems, which can lead to centralization of business logic and dumbservices. Instead, prefer _choreography over orchestration_ and _dumb middleware, with smart endpoints_ to ensure that you keep associated logic and data within serviceboundaries, helping keep things cohesive.

- **Independently Deployable** - максимальная автономность в развертывании, даже в случае breaking changes лучше реализовать _coexist versioned endpoints_, которые позволят потребителям переключиться со временем. То есть вообще ги от кого не зависеть, даже от портебителей сервиса. Модель _one-service-per-host_ позволяет по максимуму избежать ситуации, когда один сервис при деплойменте повлиял на другой развернутый там же. Техники _blue/green_ или _canary release_ позволяют отделить деплоймент от релиза, уменьшая риски того, что что-то пойдет не так после или во время релиза. Использование _consumer-driven contracts_ позволит поймать breaking changes перед тем, как они случаться. Релизить один сервис не затрагивая остальные - это норма, _потребители сервиса должны сами решить, когда они онбновяться на новую версию_.

- **Isolate Failure** - микросервисная система может быть более _resilient_, чем монолотная, но только в случае, если мы будем готовы к отказам части системы и сможем среагировать на это правильно, а отказы всегда происходят. Не следует трактовать запросы по сети как локальные, так как это скрывает реальные ошибки. Нужно помнить принципы _antifragility_ и быть готовым к failure. Установка правильных _timeouts_, понимание где и как использовать _bulkheads_ и _circuit breakers_ уменьшит влияние на систему ее упавшей части. Необходимо понимать как упавшая часть системы повлияет на пользователя. Понимание того каковы могут быть последствия _network partition_ и чем стоит пожертвовать: _consistency_ или _availability_, - это задача, решение которой даст более надужную и _resilient_ систему.

- **Highly Observable** - Испольщование _semantic monitoring_ позволяет увидеть корректноли ведет себя система, а внедерение _synthetic transactions_ эмулирует поведение пользователи в системе. _Аггрегирование логов и статистики_ и использование _correlation IDs_ позволит увидеть источник проблемы, если она возникнет и воспроизвести ее для дебага, а также в целом проследить любой запрос через несколько сервисов.

Не стоит реализовывать сразу микросервисную архитектуру когда бизнес домен еще не до конца понятен и не очевидны границы его областей, по которым можно сделать сервисы. Это касается как унаследованных монолитных систем ожидаующих переписывания, так и новых, которые только начинают реализовываться. На микросервисы нужно переходить **постепенно** с увеличением знаний в доменной области и растущей экспертизой у разработчиков.
