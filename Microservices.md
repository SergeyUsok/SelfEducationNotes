## Good practices for high-performance and scalable applications (Node.js example)

 - https://medium.com/iquii/good-practices-for-high-performance-and-scalable-node-js-applications-part-1-3-bb06b6204197
 - https://medium.com/iquii/good-practices-for-high-performance-and-scalable-node-js-applications-part-2-3-2a68f875ce79
 - https://medium.com/iquii/good-practices-for-high-performance-and-scalable-node-js-applications-part-3-3-c1a3381e1382

### Варианты горизонтального масштабирования приложения:

1. Множество процессов на одной машине (каждый процесс - это экземпляр нашего сервиса). При такой архитектуте необходимо выделить **master**-процесс и **worker**-процессы для каждого ядра. **Master**-процесс используя round-robin механизм распределяет нагрузку и входящие запросы между **worker**-процессами. С точки зрения кода, это все будет один и тот же сервис с неким if-ом, по которому собственно и определяем режим работы данного экземпляра (master или worker).

2. Все тоже самое, что и в первом случае, но используя **third-party process manager** как **master**. Для Node.js, например, это **PM2**.

3. Множество машин с сетевым **load balancing**. Согласно архитектуре, имеем несколько машин, на которых установлены несколько экземпляров нашего сервиса, то есть каждая машина представляет собой пункты 1 или 2. Балансировщик между машинами можно использовать какой-нибудь уже готовый (например, Elastic Load Balancer в AWS). Можно добавить несколько балансеров и распределять трафик между ними через DNS Resolver.

### Как сделать сервис готовым для масштабирования:

1. Необходимо разворачивать экземпляры приложения и базы данных (включая in-memory caches типа Redis) на отдельных машинах, чтобы их можно было масштабировать отдельно друг от друга.

2. Сервисы должны быть **stateless**, так как их несколько экземпляров и к какому конкретно попадет один и тот же пользователь между разными запросами - неизвестно. Конфигурации и настройки, которые могут измениться во время работы приложения, надо хранить во внешнем хранилище (база, файловая система или Redis-like база), чтобы все экземпляры могла подхватить эти изменения.

3. Аутентификация и авторизация требует хранения информации о том, что текущий пользователь залогинен и авторизован на всех экземплярах приложения, но при этом он не должен вводить свои credentials каждый раз, когда балансер переключается между экземплярами приложения. Варианты решения данной проблемы:

- Настроить Load balancer всегда перенаправлять запросы от одного и того же пользователя на один и тот же сервис. Но это довольно сложно менеджить и частичто убивает независимость сервисов и масштабирование.
- Хранить данные сессии в базе или на файле, но множественные I/O операции плохо влияют на производительность.
- Немоного проще и производительнее хранить данные в кэше типа Redis, но требует больше оперативной памяти
- Использовать JWT токены - JSON Web Tokens, хранить их на клиенте в куках и пересылать их при каждом запросе на сервер, а сам сервер уже может их процессить и проверять является ли данный токен настоящим и аутентифицирован ли пользователь. Т.к. JWT не зашифрован и просто хранится в base64, то для их передачи необходимо использовать SSL канал. 

4. Хранить user=-generated assets не в файловой системе, посколько они будут доступны только на одной машине, а в каком-то специализированном сервисе, типа S3 от Amazon и сохранять в базу только URI для этих ресурсов. Все экземпляры приложения смогут получить эти URI из базы и сами ресурсы по URI.

5. Для real-time общения между сервером и клиентом или между клиентами использовать WebSocketsа, а Redis для pub-sub функциональностии и как медиатор между экземплярами пролижения. Long-polling не подойдет поскольку требует постоянной сессии, от чего мы пытаемся уйти.

## Мысли и советы из книги Sam Newman "Building Microservices"

1. **Bounded context** из DDD отлично описывает один микросервис. Если определить все главные **bounded contexts**, то можно каждый выделить в сервис, а каждый сервис может содержать свои внутренние **bounded contexts**.

2. Систему можно начинать проектировать и делать как монолитную в одном солюшне для того чтобы постепенно проявить все внутренние (использующиеся внутри сервиса) и внешние (использующиеся для передачи данных между сервисами) **модели** и **bounded contexts**. Затем, когда все проясниться и устаканиться, можно ее (систему) разбить на микросервисы. **Это совет для новичков**. С опытом систему можно сразу проектировать как микросервисную.

3. При проектировании микросервисов необходимо думать в **контексте возможностей (capabilities)** проектируемого сервиса и того **что он умеет делать**, а не данных которыми он оперирует, иначе выйдет просто CRUD вокруг которого строится сервис. А когда эти возмоности и способности определены - уже можно выделять данные и модели, которые нужны для реализации этих спосбностей.

4. Вариант общения клиента и сервера: гуглить **Richardson Maturity Model и Hypermedia Controls (HATEOAS)**. Фаулер об этом писал, подход прикольный, но походу не получил популярность.

5. Микросервисы должны иметь **low coupling** между друг другом и **high cohesion** внутри себя, что логично. Но **shared** между сервисами база данных или **библиотека с data types** для всех сервисов в итоге неявно увеличивает **coupling**. Кроме того, создание библиотеки клиента для сервиса и использование ее в разных клиентах этого сервиса тоже создает **coupling** между **ВСЕМИ** клиентами и сервисом. Принцип **DRY** тоже можно и нужно нарушать в угоду независимости сервисов друг от друга. Лучше скопипастить какой-то кусок кода с бизнес логикой чем выделять его в библиотеку и шарить ее между сервисами (речь не идет вспомогательных библиотеках типа log4net).

6. Согласно автору **асинхронная event-based** коммуникация между микросервисами через **message broker** типа Rabbit MQ является лучшим вариантом реализации архитектуры микросервисов, так как имеет наименьший **coupling** и микросервисы не знают друг о друге.

7. UI layer за которым стоит множество микросервисов может общаться с ними следующим образом:
	* UI компонент, который шлет запросы всем необходимым сервисам
		- &#9989; SRP - UI сам за себя отвечает и знает что ему нужно
		- &#10060; сообщения могут слаться рассинхронизированно, что жрет много трафика, что критично для мобильной сети
		- &#10060; для получения всей информации надо общаться с несколькими сервисами, т.е. происходит интенсивное использование сети
		- &#10060; скорее всего понадобиться выделенная команда для поддержи UI, а это значит необходима коммуникация между командами, теряется независимость
		- &#10060; увеличиватся **coupling** между сервисами и UI
	
	* Каждый сервис представляет свой UI виджет. Все они собираются в некий box и показываются пользователю.  
		- &#9989; UI каждого сервиса сапортится командой этого сервиса и нет нужды в выделенной UI команде
		- &#9989; **coupling** между UI и сервисами в порядке
		- &#10060; сообщения все равно могут слаться рассинхронизированно, что жрет много трафика, что критично для мобильной сети
		- &#10060; для получения всей информации надо общаться с несколькими сервисами, т.е. происходит интенсивное использование сети
		- &#10060; в случае появления виджета, которому необходимы данные нескольких сервисов снова увеличивается **coupling**		
	* **API Gateway**, что по сути является **фасадом** ко всем сервисам. 
		- &#9989; сервисы и UI независимы друг от друга и развязаны через Gateway
		- &#9989; данные из разныих сервисов могут быть получены UI одном запросом к фасаду, который уже сам знает какие сервисы ему запросить
		- &#10060; при изменении одного сервиса меняется фасад
		- &#10060; фасад может разрастись до огромных размеров и его будет тяжело поддерживать, особенно если учитывать разные виды UI (mobile, web, admin panel) которые могут иметь потребности в разных сервисах, но в итоге объединенный одним фасадом
	
	* Альтернативой, поддерживаемой автором, является **Гибридный подход**, где каждый вид UI (mobile, web, admin panel) имеет свой **API Gateway** (backend-for-frontends)
		- &#9989; сервисы и UI независимы друг от друга и развязаны через Gateway
		- &#9989; разные виды UI независимы друг от друга и от сервисов
		- &#9989; данные из разныих сервисов могут быть получены UI одном запросом к фасаду, который уже сам знает какие сервисы ему запросить
		- &#9989; меньше шансов, что фасад разрастется до огромных размеров
		- &#9989; при изменении одного сервиса меняется только зависимый фасад, если таковой есть
		- &#10060; необходимо поддерживать больше одного фасада
		- &#10060; возможно понадобится выделенная команда, с которой другим надо коммуницировать, что уменьшает независимость
		- &#10060; при изменении сервиса используемого в нескольких фасадах, их придется менять все

8. При необходимости использования какого-либо решения, как архитектор, нужно решить стоит ли это решение писать саммим или взять/купить готовое и внедрить. Опасность готовых решений может быть в том, что оно не полностью подходит и его надо кастомизировать под себя, что бывает не так просто и может дорого стоить и, возможно, проще что-то переделать у себя, чтобы это решение начало работать "из коробки" либо все же написать самим что-то, что не такое громоздкое и гибкое для кастомизации, но подходит идеально под нужды проекта.

9. **Prefer Choreography (event-based communication) over Orchestration (existing of some broker which redirects calls from one microservice to another and knows about all microservices)**

### Политика работы с базами данных в Микросервисной архитектуре

1. Избегать **foreign keys** в базах и соединять данные в коде сервисов, поскольку это соединение является частью бизнес-логики. Таком образом, мы избавляемся от лишнего **coupling** внутри базы данных. Недостатком данного подхода является увеличение количества обращений к базе.

2. Для того, чтобы один сервис не тянул данные из разных таблиц, о которых по логике ему не положено знать, модно сделать API call к другому сервису, которые оперирует данными из другой таблицы. Но в случае этого call'a не тащить **все** данные, а только **нужные**. Проблемой здесь является то, что теперь все **consistency checks** ложатся на плечи сервисов.

3. **Shared Static data** желательно тоже не хранить в общей таблице, а продублировать эти данные для каждого сервиса, или вообще положить их как часть кода каждого сервиса или выделить в отдельный сервис, если существует сложная бизнес-логика связанная с этими данными. Все ради уменьшения **coupling**, даже дублирование данных (х.з., стоит ли оно того).

4. **Shared Dynamic data**, например **Customer data**, которые могут быть нужны нескольким сервисам (Order, Discount, Delivery etc.) возможно стоит выделить в отдельный **Customer service** и обращаться к нему из разных сервисов, а он сам по себе будет уже управлять данными о **Customers**.

5. **Shared tables**, случай похожий на предыдущий, но в выделении отдельного сервиса нет смысла, так как не проглядыватся bounded context или какой-то сложной логики работы с данной таблицей. Тогда, можно саму таблицу разбить на столько частей, сколько сервисов ее использует и записать в каждую из новых таблиц только те данные, которые нужны конкретному сервису.

6. Книга **Refactoring Databases by Scott J Amber** в помощь

7. При рефакторинге монолитной архитектуры в микросервисную надо разбивать базу и выделяит сервисы **поэтапно**, тестируя изменения на каждом этапе.

8. При существовании множества сервисов обращающихся к базе появляется понятие **distributed transaction** и **eventual consistency**. Есть разные способы для работы в такой парадигме
	- **compensating transaction** - если одна из частей транзакции провалилась (вставка в данных разные таблицы разными сервисами в рамках одной бизнес-операции), то запускается механизм отката уже свершившихся частей транзакции. Проблема здесь в том, что **compensating transaction** тоже может провалиться, тогда нужен какой-то **retry** или **clean up/reconciliation**  по расписанию, но менеджить транзакции состоящие из 3-х, 4-х, 5-ти... частей все равно становиться слишком сложно.
	- **two-phase commit**. С этим подходом сначала идет **voting phase**, где каждый учасник транзакции (называемый _cohort_) говорит **transaction manager**, что он готов к обработке транзакции. Каждый учасник должен сказать _yes_, тогда **transaction manager** сообщает всем учасникам, что они могут выполниьт свои часть транзакции, а в случае хотя бы одного _no_ вся транзакция не выполняется. Здесь все равно есть риск, что какой-то участник провалит свою часть транзакции даже после того как он отправил _yes_, поэтому действует предположение, что после _yes_ транзакция выполнится в любом случае. Кроме того, присутствует _bottleneck_ в виде **transaction manager** от которго все зависят. Процесс координирования также означает наличие **lock'ов** на данных пока идет транзакция, что в случае **outage** влияет на всю систему и плохо для масштабирования.
	- в итоге, если часть системы нуждается в **реальной постоянной согласованности**, возможно, ее не стоит биь на части в виде микросервисов и отдельных вызовов к базе. Тогда транзакции можно отдать на откуп базе данных, в чем она хороша. Иначе же, можно обойтись **eventual consistency**.
	
9. В части **REPORTING** (примерно стр. 174) дается несколько советов о том, как можно организовать **reporting** часть системы. Здесь описывать все нет смысла, лучше обратиться к первоисточнику.

### Deployment и CI/CD в мире микросервисов

1. Желательно делать билды для каждого микросервиса отдельно и ребилдить только тот микросервис, который был изменен а не всю экосистему сервисов. Исключением является случай, когда разработка новой системы или рефакторинг монолита в микросервисы только начинается и границы сервисов и их API еще не определены, поэтому имеет смысл бандлить все **пока** как один солюшн и один билд.

2. **Build pipeline** - это концепция поэтапной сборки, интергрирования и развертывания приложения. В случае проблем на каком-то из этапов нет необходимости начинать следующий этап. **Build pipeline** дает возможность отслеживать прогресс изменений software и контролировать его качество. Релиз процесс как **build pipeline:**

_Compile and fast tests_ -> _Slow tests_ -> _UAT_ -> _Performance tests_ -> _Production_

3. **Continuous delivery (CD)** построено на концепции **Build pipeline** и является подходом, при котором мы получаем постоянный feedback о готовности к production release для каждого коммита и трактуем каждый коммит как release-кандидат.

4. Варианты хостинга сервисов
	- Multiple services per host
	- Application container with multiple services inside per single host
	- Single service per host
	- PaaS

5. **Автоматизация** - ключ к простоте управления (handling) множеством сервисов. Перед переходом с монолита на микросервисы прежде всего необходимо автоматизировать процессы сборки, развертывания и мониторинга, а после уже рефакторить и переделывать систему.

9. В части **From Physical to Virtual** (примерно стр. 217) говорится о **контейнеризации** и **виртуализации**, упоминаются несколько полезных инструментов, в том числе и Docker.

10. **SUMMARY**
	- Focus on maintaining the ability to release one service independently from another, and make sure that whatever technology you select supports this.
	- Author suggests to have a single repository per microservice and one CI build per microservice for deploying them separately.
	- Have single-service-per-host/container (use Docker or LXC to make managing the moving parts cheaper and easier)
	- Automate everything, if choosen technology does not allow automation, choose another technology, because **automation is a KEY to easy manageability**
	- Going deeper into this topic read the book by Jez Humble and David Farley "Continuous Delivery" 

### Тестирование микросервисов

1. Brian Marick's testing quadrant:

![Brian Marick's testing quadrant](https://lisacrispin.com/wp-content/uploads/2011/11/Agile-Testing-Quadrants.png)

2. Mike Cohn's test pyramid

![Mike Cohn's test pyramid](https://martinfowler.com/articles/practical-test-pyramid/testPyramid.png)

3. **Unit tests** - это **small-scoped** тесты и их главная цель дать **быстрый** _feedback_ о том насколько хорошо написанная функциональность работает.

4. **Service tests** - тестируют возможности и функциональность отдельного сервиса. Можно сказать, это **middle-scoped** тесты, они могут быть быстрыми как unit, так и долго выыполняющимися при, например, интеграции с реальной базой или другими сервисами.

5. **End-to-end tests (UI in Mike Cohn's test pyramid)** - тесты для всей системы в целом. Это **large-scoped** тесты. Когда они успешно выполняются можно быть более-менее уверенным, что система работает (при условии, что тесты написаны корректно).

6. Чем больше **testing scope** тем медленней тесты работают и долшье ждать feedback. Однако чем более изолированней тесты (меньше scope) тем меньше информации о том как система себя поведет в целом.

7. Следуя принципу **Fail fast** в build pipeline необходимо настраивать тестовый прогон в порядке увеличения **testing scope**, т.е. сначала unit, потом service, а потом end-to-end тесты.

8. Есть несколько проблем с **large-scoped** тестами:
	- В случае с интеграционными тестами (service tests) или end-to-end тестами, какие версии других сервисов (от которых зависит наш тестируемый) брать для тестирования? Продакшн версии или последнии из UAT?
	- При наличии в активной разработке нескольких сервисов, как ранить end-to-end тесты и трактовать их результаты, если несколько сервисов были изменены?

Эти проблемы можно решить наличием нескольких веток build pipeline'ов с unit и service тестами, которые при положительном результате каждой ветки объединиются и ранять общие для всех end-to-end tests.

Еще одной проблемой end-to-end тестов в случае, когда есть несколько команд и каждая отвечает за свой сервис, является то, что не очевидно, кто должен реагировать, если они упали. Решением может быть дежурства каждой команды, по-спринтово, например.

9. **Test Journeys, Not Stories**. Это значит, что не надо добавлять на каждую user-story по end-to-end тесту, поскольку они обычно долго ранятся и управлять ими и их зависимостями сложно, то в end-to-end лучше добавлять тесты, которые проверяют **core** логику системы, а user-story лучше проверять в service тестах в изоляции. **Core логика** - это например, flow заказа в онлайн магазине, начиная от UI и заканчивая доставкой и оплатой и все это один end-to-end тест, который должен работать всегда, независимо от изменений в сервисах.

10. **Consumer-driven contract (CDC)** - это концепция тестирования сервиса с точки зрения _потребителя_ этого сервиса. На пирамиде Mike Cohn'a эти тесты находятся рядом с service тестами, так как тестируют конкретный сервис. Преимущество данных тестов перед обычными интеграционными в том, что они тестируют конкретный реальный сценарий. Кроме того, они могут тестировать **разную** функциональность одного и того же сервиса, но с точки зрения **разных** потребителей. Например, у нас есть _Customer_ сервис, отвечающий за клиентов. У данного сервиса 2 потребителя: _Customer helpdesk_ service и _Delivery_ service. Оба сервиса имеют свои ожидания (expectations) о том, как _Customer_ сервис должен работать. Соответственно создаются два набора **CDC** тестов для каждого аспекта работы _Customer_ сервиса. Хорошей практикой является создание этих тестов в коллаборации между командами _Customer_ и _Customer helpdesk_ сервисов и _Customer_ и _Delivery_ сервисов. Преимущество данных тестов в том, что в случае проблем с тестом, сразу видно какой _потребитель_ заимпакчен. Pact: [link to Pact!](https://github.com/pact-foundation/pact.io) - инструмент для **CDC** тестов.

11. Автор советует предпочесть **CDC** и заменить ими end-to-end тесты, исходя из его опыта и опыта его знакомых, это работает, при этом **CDC** требуют меньше времени для работы, так как имеют меньший _scope_, и более информативны в определении проблемных мест.

12. **TESTING AFTER PRODUCTION**. Не всегда testing environment полностью повторяет production, соответственно во время релиза возникает необходимость протестировать сервисы уже после релиза на production environment'е. Несколько вариантов реализации такого тестирования:
	- _smoke test suite_ - небольшой набор тестов, который прогоняется после релиза и направлен на то, чтобы протестировать места где environment различается между UAT и Production.
	- _blue/green deployment_ - с этим подходом мы имеем 2 копии системы развернутых одновременно, но только одна получает реальные requests. Т.о. старая версия пока работает, а с новой версией прогоняются _smoke tests_. Если тесты в порядке, то мы переключаем систему со старой версии на новую.
	- _canary releasing_ - чем-то схож с _blue/green deployment_, но смысл в том, что мы **постепенно** переключаем proudction со старой версии на новую, когда обе развернуты на production. Каждый раз, переключая какую-то часть системы сос старой на новую, мы проверяем, что она справляется с нагрузкой и функционально ведет себя правильно. На каждом этапе, в случае каких-либо проблем, мы имеем возможность откатить систему. С таким подходом можно также копировать запросы, которые идут к старой production системе, в новую и сравнивать как они себя ведут. Netflix использует _canary releasing_.
	
13. Нужно учитывать, что какими бы не были отличными тесты и какое бы покрытие не было бы достигнуто - от всех проблем не удастся избавиться и они однажды проявятся на проде. Здесь в игру вступает **Mean Time to Repair (MRTR) vs Mean Time Between Failures (MTBF)**. Необходимо искать компромисс между этими характеристиками системы и иметь большой MTBF (что обеспечивается хорошими тестами), но и иметь адекватный MRTR и быть готовым ко сбоям в системе, то есть иметь некую стратегию на случай отказа системы.

14. Большой объем тестов кроется под термином **nonfunctional tests**, которые автор предпочитает называть **cross-functional tests**, поскольку они охватывают различные аспекты системы (performance, UI validity in terms of HTML, HTML accessability for disabled people, scalability, etc.) Такие тесты обычно возможно провести только на проде в реальных условиях, но во время разработки и тестирования, по крайней мере, можно разработать стретегии тестирования и трекать, движемся ли мы в правильном направлении. С учетом широкого охвата различных аспектов системы данными тестами, их можно и нужно приоритезировать и учитывать, так как часто надежность и доступность одного аспекта системы важнее другого, например надежность платежного сервиса явно важнее чем произодительность рекомендательного. Автор советует учитывать данные тесты с ранних стадий разработки, а не откладывать их на потом.

15. **Performance Tests**. Пожалуй, в мире микросервисов, Performance Tests еще важнее чем в Монолите, поскольку теперь появляются множество акторов, которые взаимодействуют между собой по сети, каждый из них может обращаться к базам данных, что увеличвает в целом количество IO операций по сравнению с Монолитом. Данные тесты практически бесполезны в изоляции, поэтому часто из откладывают на потом, но автор советует покрывать ими Core части системы и основные Journes, даже когда вся система еще не написана. Понятно, что данный тип тестов требует prod-like окружения и объемов данных, сами тесты могут выполняться долго, поэтому хорошей практикой является прогон некоторого подмоножества тестов каждый день и основного множества раз в неделю. **Важным также является определить цели (targets) этих тестов, то есть числа производительности, по которым можно понять, что тест прошел или упал.** Иначе есть шанс, что на результаты никто не будет обращать внимания.

### Monitoring

**Monitor the small things, and use aggregation tosee the bigger picture**.

Logging is a key to proper monitoring. Some tools mentioned by author:
- **Kibana** is an ElasticSearch-backed system for viewing logs
- **Graphite** is an system for storing, querying and viewing metrics. It allows view aggregated metrics for the whole system (e.g. CPU load), aggregated metrics for all instances if concrete service or just concrete instance of concrete service.

Автор рекомендует, чтобы сервисы свои базовые выставляли наружу сами по себе. Это облегчит мониторинг для внешних инструментов и даст понимание какие фичи данныъ сервисов используются чаще, чем другие. Например, Customer service может выдавать метрику о том, сколько покупателей и как часто смотрят на свои предыдущие заказы. Это полезно знать, например, для того нужно ли дальше поддерживать фичу или стоит ее как-то улучшить или оптимизировать.

**Synthetic transaction** - транзация, которая запускает в цепь событий и калькуляций в системе имитирующих реальные события и калькуляции. **Semantic monitoring** - техника, с использованием **Synthetic transaction**, собиранием метрик на основе данной транзации и последующая оценка данных метрик.

В микросервисной архитектуре множество сервисов общаются между собой, что приводит к сложной цепочки вызовов. Если на каком-то этапе произойдет ошибка, будет трудно отследить в логах какой именно вызов привел к ней, так как сервисы обрабатываебт множество вызовов одновременно. Для целей отслеживания всей цепи вызовов инициированной конкретным вызовом автор рекмендует использовать **Correlation ID** - механизм, с помощью которого можно отслеживать цепочку вызовов-ответов между различными сервисами. Инициирующий некую служную (требующую участия множества сервисов) операцию сервис генерирует уникальный **Correlation ID** и пробрасывает его дальше в вызовах, последующие сервисы, видя наличие ID, тоже пробрасываеют его дальше и логируют. Т.о. можно отследить в логах конкретный реквест.

Track the health of all downstream responses, at a bare minimum including theresponse time of downstream calls, and at best tracking error rates. Libraries likeHystrix can help here.

Автор советует иметь некую стандартизацию в логах сервисов, для того чтобы было проще аггрегировать информацию. Например, один сервис может писать ResponseTime в логах, а другой RspTimeSecs, хотя эти данные значат одно и тоже. Вот для этого и нужно стандартизировать внутри команд такие core вещи.

Книга этого же автора про мониторинг: [https://www.oreilly.com/webops-perf/free/lightweight-systems.csp]

### Security


